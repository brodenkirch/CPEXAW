{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "340df700-88d2-4b4a-afb2-fe5ea3df0120",
   "metadata": {},
   "source": [
    "## CPEX Field Campaign Series ERA5 Reanalysis of Convective Inflow and Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929c7d5",
   "metadata": {},
   "source": [
    "This script is an adapted version of \"CPEXCV_ERA5_3DWind_EXAMPLE_Giselle.ipynb\"\n",
    "\n",
    "Code for plotting streamlines and convergence from ERA5 Reanalysis (https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5) at select times and pressure levels.\n",
    "\n",
    "(Note from Giselle: the smoothing on the example plot isn’t needed. There’s some pressure levels for which the smoothed streamlines are not correctly plotted, and I so removed the smoothing code on the template, so you don’t have to worry about that. If you want to use the example code, I would suggest to remove the smoothing for the streamlines.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27196f-8817-402e-810d-dc421c14510a",
   "metadata": {},
   "source": [
    "This notebook plots ECMWF ERA5 reanalysis data (3-D hourly gridded winds with 0.25 degree resolution) to give context for the large-scale flow and where the near-storm dropsondes are located relative to the convective inflow region(s).\n",
    "\n",
    "#### <span style=\"color:purple\"> Plotting streamlines at each hour: </span>\n",
    " \n",
    "- Low-level Inflow: $975 \\: hPa, 950 \\: hPa, 925 \\: hPa$\n",
    "- Mid-level Inflow: $775 \\: hPa, 750 \\: hPa, 700 \\: hPa$\n",
    "\n",
    "- Low-level Convergence: $1000 \\: hPa, 975 \\: hPa, 950 \\: hPa, 925 \\: hPa$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb4b4b-3c80-47b7-b52e-fca8ce2a99b9",
   "metadata": {},
   "source": [
    "#### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313778c-2d18-4aab-a971-43127086bca1",
   "metadata": {},
   "source": [
    "[ECMWF Reanalysis ERA5](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633adcce-bc2c-421c-b714-8c8cf0e13007",
   "metadata": {},
   "source": [
    "### ERA5 Reanalysis -- 3D Winds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058e42d-0688-4460-bc27-7ba0d3fc1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import h5py\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm  #to get python's normal library of colormaps\n",
    "import matplotlib.colors as mplc\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "#from cartopy.util import add_cyclic_point\n",
    "#from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import metpy.calc as mpcalc\n",
    "#import metpy.plots as mplots\n",
    "\n",
    "from PIL import Image\n",
    "import icartt            #needed to read .ict files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dcf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "###the only variables you need to change are the 2 in this cell\n",
    "pressures_to_plot_stream = [975, 950, 925, 775, 750, 700]   #desired pressure levels to be plotted for streamlines\n",
    "pressures_to_plot_conv = [1000, 975, 950, 925]              #desired pressure levels to be plotted for convergence\n",
    "pressures_to_plot_RH = [850, 800, 750, 700]                 #desired pressure levels to be plotted for RH for convergence plots\n",
    "\n",
    "#dict of desired flight dates (key) to plot ERA5 streamlines/convergence for and\n",
    "#their associated list of desired UTC hours to be plotted (e.g., convective case hours/time range)\n",
    "\n",
    "#CPEX and CPEX-AW convective cases (also plotting +/- 4 hours around convective cases)\n",
    "case_dict_stream = {'20220906': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
    "                   '20220907': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
    "                   '20220909': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
    "                   '20220910': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
    "                   '20220914': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
    "                   '20220916': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
    "                   '20220920': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "                   '20220922': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "                   '20220923': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "                   '20220926': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n",
    "                   '20220929': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
    "                   '20220930': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}\n",
    "case_dict_conv = case_dict_stream\n",
    "\n",
    "# #CPEX and CPEX-AW convective cases\n",
    "# case_dict_stream = {'20170601': [18, 19, 20, 21, 22],      \n",
    "#              '20170602': [18, 19, 20, 21, 22],\n",
    "#              '20170606': [19, 20, 21, 22],\n",
    "#              '20170610': [20, 21, 22, 23],\n",
    "#              '20170611': [17, 18, 19, 20, 21, 22],\n",
    "#              '20170615': [19, 20, 21],\n",
    "#              '20170616': [19, 20, 21, 22],\n",
    "#              '20170617': [19, 20, 21, 22],\n",
    "#              '20170619': [17, 18, 19, 20, 21, 22, 23],\n",
    "#              '20170620': [17, 18, 19, 20, 21, 22],\n",
    "#              '20170624': [18, 19, 20, 21, 22],\n",
    "#              '20210821': [22, 23],\n",
    "#              '20210822': [0, 1, 2],\n",
    "#              '20210824': [18, 19, 20, 21]}\n",
    "\n",
    "# #CPEX(-AW) cases 13 and 16\n",
    "# case_dict_stream = {'20170611': [14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
    "#                   '20210824': [15, 16, 17, 18, 19, 20, 21]}\n",
    "# case_dict_conv = {'20170611': [14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
    "#                   '20210824': [15, 16, 17, 18, 19, 20, 21]}\n",
    "\n",
    "# #for testing\n",
    "# case_dict_stream = {'20170611': [19]}   #for testing\n",
    "# case_dict_conv   = {'20210824': [15]}   #for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c78f9-a567-41fb-b251-20110ba87c6f",
   "metadata": {},
   "source": [
    "#### Streamlines at Various Pressure Levels with flight track and dropsondes overlaid for each desired flight and time ranges in case_dict_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47a48a-7eda-427f-a3f1-a783d25a2ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #set some baseline plot displays\n",
    "\n",
    "# #matplotlib.rcParams['axes.facecolor'] = [0.9,0.9,0.9]\n",
    "# matplotlib.rcParams['axes.labelsize'] = 20\n",
    "# matplotlib.rcParams['axes.titlesize'] = 20\n",
    "# matplotlib.rcParams['axes.labelweight'] = 'bold'\n",
    "# matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "# matplotlib.rcParams['xtick.labelsize'] = 16\n",
    "# matplotlib.rcParams['ytick.labelsize'] = 16\n",
    "# matplotlib.rcParams['legend.fontsize'] = 16\n",
    "# #matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "# #matplotlib.rcParams['axes.facecolor'] = 'w'\n",
    "# matplotlib.rcParams['font.family'] = 'arial'\n",
    "# matplotlib.rcParams['hatch.linewidth'] = 0.3\n",
    "\n",
    "# #file_date is the date on which the desired flight took place\n",
    "# #utc_hours_to_plot is the desired UTC hours to be plotted for the given flight (e.g., convective case hours/time range)\n",
    "# for file_date, utc_hours_to_plot in case_dict_stream.items():\n",
    "\n",
    "#     print (file_date + ' streamline plots in progress...')\n",
    "    \n",
    "#     ###get locations of the dropsonde/Navigation/ERA5 folder and read the appropriate files in\n",
    "#     day_folder = os.path.join(os.getcwd(), file_date)\n",
    "\n",
    "#     #dropsonde data\n",
    "#     drop_csv_path = os.path.join(day_folder, 'final_dropsonde_' + file_date + '.csv')\n",
    "#     drop_csv = pd.read_csv(drop_csv_path)\n",
    "\n",
    "#     if file_date[:4] == '2017':\n",
    "#         campaign = 'CPEX'\n",
    "#         drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "#     elif file_date[:4] == '2021':\n",
    "#         campaign = 'CPEXAW'\n",
    "#         drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "#     elif file_date[:4] == '2022':\n",
    "#         campaign = 'CPEXCV'\n",
    "#         drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations_CPEXCV.csv')\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "#     #ERA5 data\n",
    "#     era5_folder = os.path.join(os.getcwd(), 'ERA5_Reanalysis_Data')\n",
    "#     era5_path = os.path.join(era5_folder, campaign + '_ERA5_Reanalysis_Hourly_Pressure.nc')\n",
    "#     ds = xr.open_dataset(era5_path)\n",
    "\n",
    "#     #Navigation data\n",
    "#     nav_folder = os.path.join(day_folder, 'Nav_files')\n",
    "\n",
    "#     for x in os.listdir(nav_folder):\n",
    "#         if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "#             os.remove(os.path.join(nav_folder, x))\n",
    "\n",
    "#     nav_ict_path = os.path.join(nav_folder, os.listdir(nav_folder)[0])  #only one nav file per flight\n",
    "\n",
    "#     if campaign != 'CPEX':  #campaign either CPEXAW or CPEXCV\n",
    "\n",
    "#         nav_ict = icartt.Dataset(nav_ict_path)    #open the ict file with icartt\n",
    "#         flight_lat = nav_ict.data[\"Latitude\"]     #nav latitude, just a normal 1-D array\n",
    "#         flight_lon = nav_ict.data[\"Longitude\"]    #nav longitude, just a normal 1-D array\n",
    "\n",
    "#     else:  #for CPEX navigation files, open the CSV file with pandas\n",
    "#            #(Navigation files for CPEX (2017) are originally .kmz not .ict,\n",
    "#            #so I converted them to CSV for free using https://www.gpsvisualizer.com/convert_input\n",
    "\n",
    "#         nav_ict = pd.read_csv(nav_ict_path)       #open the ict file with pandas instead\n",
    "#         flight_lat = nav_ict[\"latitude\"].values   #nav latitude, just a normal 1-D array\n",
    "#         flight_lon = nav_ict[\"longitude\"].values  #nav longitude, just a normal 1-D array    \n",
    "\n",
    "#     #flight track lat/lon extent [West,East,South,North] for plotting, giving an XX degree buffer around the flight track   \n",
    "#     campaign_extent = [flight_lon.min() - 2.5, flight_lon.max() + 2.5, flight_lat.min() - 2.5, flight_lat.max() + 2.5]\n",
    "\n",
    "\n",
    "#     ###calculate each near-storm dropsonde's mean lat/lon and add the sonde's time and mean lat/lon to a list to be plotted\n",
    "\n",
    "#     drop_coords_and_time = []   #format: longitude, latitude, time (HHSS)\n",
    "\n",
    "#     df_drop = pd.read_csv(drop_metric_filepath)\n",
    "#     df_drop_use = df_drop[df_drop['Date'] == int(file_date)].copy()\n",
    "\n",
    "#     for x in range(len(df_drop_use)):\n",
    "#         date = str(df_drop_use['Date'].iloc[x])\n",
    "#         time = str(df_drop_use['Time'].iloc[x]).zfill(6)\n",
    "#         sonde_datetime = date[:4] + '-' + date[4:6] + '-' + date[6:] + ' ' + time[:2] + ':' + time[2:4] + ':' + time[4:]\n",
    "\n",
    "#         drop_csv_use = drop_csv[drop_csv['Time [UTC]'] == sonde_datetime].copy()\n",
    "#         drop_mean_lon = drop_csv_use['Longitude [deg]'].mean()\n",
    "#         drop_mean_lat = drop_csv_use['Latitude [deg]'].mean()\n",
    "\n",
    "#         sonde_info = [drop_mean_lon, drop_mean_lat, time[:4]]\n",
    "#         drop_coords_and_time.append(sonde_info)\n",
    "\n",
    "        \n",
    "#     ###create an XX-panel plot of streamlines at XX-different pressure levels \n",
    "#         ###for each desired hour of the given day\n",
    "\n",
    "#     half_pres_levs = math.ceil(len(pressures_to_plot_stream) / 2)   #to determine size of figure and number of subplots to generate (rounded up to the nearest multiple of 2)\n",
    "\n",
    "#     for hr in utc_hours_to_plot:\n",
    "        \n",
    "#         hr2 = str(hr).zfill(2)\n",
    "#         hour_prior = str(hr - 1).zfill(2)\n",
    "\n",
    "#         #MIMIC TPW data\n",
    "#            ##https://bin.ssec.wisc.edu/pub/mtpw2/data/\n",
    "#         tpw_folder = os.path.join(day_folder, 'MIMIC_TPW_files')\n",
    "#         tpw_path = os.path.join(tpw_folder, 'comp' + file_date + '.' + hr2 + '0000.nc')\n",
    "#         ds_tpw = xr.open_dataset(tpw_path)\n",
    "\n",
    "#         #GPM IMERG data (see IMERG.ipynb for more how to more generally download and plot IMERG data)\n",
    "#            ##https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Read%20IMERG%20Data%20Using%20Python\n",
    "#            ##https://disc.gsfc.nasa.gov/datasets?keywords=imerg&page=1\n",
    "#            #0.1 x 0.1 gridded data, half-hourly means, using the half hour BEFORE the desired hour\n",
    "#         imerg_folder = os.path.join(day_folder, 'IMERG_files')\n",
    "        \n",
    "#         for x in os.listdir(imerg_folder):\n",
    "#             if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "#                 os.remove(os.path.join(imerg_folder, x))\n",
    "                \n",
    "#             #minutes and seconds automatically revert to zero (hour = 0, seconds = 0) for '%Y%m%d%H'\n",
    "#             elif (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(seconds = 1), '%H%M%S') in x) and (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(minutes = 30), '%H%M%S') in x):\n",
    "#                 imerg_file = x\n",
    "#                 break\n",
    "#             else:\n",
    "#                 imerg_file = 'Could not find the desired IMERG file'\n",
    "        \n",
    "#         #confirm that the IMERG file is from the correct day (if hr2 == '00', then this will be the previous day)\n",
    "#         assert (file_date in imerg_file) or (hr2 == '00'), 'IMERG file not from the correct day'\n",
    "        \n",
    "#         imerg_path = os.path.join(imerg_folder, imerg_file)\n",
    "#         ds_imerg = h5py.File(imerg_path, 'r')\n",
    "        \n",
    "#         imerg_lons = ds_imerg['Grid/lon'][:]   #Longitude Shape: (3600,)\n",
    "#         imerg_lats = ds_imerg['Grid/lat'][:]   #Latitude Shape: (1800,)\n",
    "#         imerg_lons, imerg_lats = np.meshgrid(imerg_lons, imerg_lats)  #Long and lat grid shape: (1800, 3600) \n",
    "        \n",
    "#         imerg_precip = ds_imerg['Grid/precipitation'][0][:][:]  #Original Precip Shape: (1, 3600, 1800) = (time, lon, lat)\n",
    "#         imerg_precip = np.transpose(imerg_precip)               #New Precip Shape after transpose: (1800, 3600)\n",
    "        \n",
    "#         #mask blank data\n",
    "#         imerg_precip_masked = np.ma.masked_where(imerg_precip < 0, imerg_precip)  #masks blank and bad data first (if blank data is -999 instead of NaN)\n",
    "#         imerg_precip_masked = np.ma.masked_where(np.isnan(imerg_precip_masked), imerg_precip_masked)  #masks NaN values (not masked in previous line)        \n",
    "        \n",
    "#         data_proj = ccrs.PlateCarree()\n",
    "\n",
    "#         group_fig = plt.figure(figsize = (12 * half_pres_levs, 5 * half_pres_levs))   #initialize the streamline figure for the given hour\n",
    "\n",
    "#         for ii, pres_lev in enumerate(pressures_to_plot_stream):\n",
    "#             ax = group_fig.add_subplot(2, half_pres_levs, ii+1, projection = data_proj)        \n",
    "\n",
    "#             uwnd = ds.u.sel(time = file_date).sel(level = pres_lev)  #zonal winds (m/s)\n",
    "#             uwnd = uwnd.sel(time = uwnd.time.dt.hour.isin(hr))       #zonal winds (m/s)\n",
    "\n",
    "#             vwnd = ds.v.sel(time = file_date).sel(level = pres_lev)  #meridional winds (m/s)\n",
    "#             vwnd = vwnd.sel(time = vwnd.time.dt.hour.isin(hr))       #meridional winds (m/s)\n",
    "            \n",
    "#             rh = ds.r.sel(time = file_date).sel(level = pres_lev)    #relative humidity (%)\n",
    "#             rh = rh.sel(time = rh.time.dt.hour.isin(hr))             #relative humidity (%)\n",
    "\n",
    "#             ##Smoothing (source: Hannah Zanowski) --> not recommended, see top of document\n",
    "#                 ##Metpy smooth_n_point (data to be smoothed, number of points to use in smoothing (5 to 9 are valid), and number of times the smoother is applied)\n",
    "#                     ##see https://unidata.github.io/MetPy/latest/api/generated/metpy.calc.smooth_n_point.html for more info\n",
    "#             #uwnd_smoothed = mpcalc.smooth_n_point(uwnd,9,10)\n",
    "#             #vwnd_smoothed = mpcalc.smooth_n_point(vwnd,9,10)\n",
    "\n",
    "#             #ax.set_title('MIMIC TPW, GPM IMERG, and \\n%i hPa Streamlines (%s, %s UTC)' % (pres_lev, file_date, hr2))\n",
    "#             ax.set_title('ERA5 %i hPa RH, GPM IMERG, and \\n%i hPa Streamlines (%s, %s UTC)' % (pres_lev, pres_lev, file_date, hr2))\n",
    "#             ax.set_extent(campaign_extent, ccrs.PlateCarree()) #lat/lon bounds are [West,East,South,North]\n",
    "\n",
    "#             # Add land, coastlines, and borders\n",
    "#             #ax.add_feature(cfeature.LAND, facecolor='0.8')\n",
    "#             ax.coastlines(ls = '-', linewidth = 0.5, color = 'gray')\n",
    "            \n",
    "# #             #plot MIMIC TPW\n",
    "# #             tpw_levels = np.arange(0, 70.5, 2)\n",
    "# #             pm0 = ax.contourf(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, levels = tpw_levels,\n",
    "# #                               extend = 'max', cmap = cm.jet, transform = data_proj)\n",
    "# # #             pm0 = ax.pcolormesh(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, vmin = 0, vmax = 70,\n",
    "# # #                                 cmap = cm.jet, transform = data_proj, zorder = 0)\n",
    "\n",
    "#             #plot ERA5 RH\n",
    "#             tpw_levels = np.arange(0, 100.1, 2)  #actually RH levels, but keeping the tpw_levels name because we use it elsewhere\n",
    "#             pm0 = ax.contourf(ds.longitude, ds.latitude, rh[0].values, levels = tpw_levels,\n",
    "#                               extend = 'max', cmap = cm.jet, transform = data_proj, alpha = 0.6)\n",
    "#         #             pm0 = ax.pcolormesh(ds.longitude, ds.latitude, rh[0].values, vmin = 0, vmax = 70,\n",
    "#         #                                 cmap = cm.jet, transform = data_proj, zorder = 0)\n",
    "    \n",
    "#             #plot IMERG Rain Rate\n",
    "#             pm1 = ax.contourf(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "#                               levels = np.logspace(np.log10(0.1), np.log10(40), num = len(tpw_levels)), \n",
    "#                               norm = 'log', extend = 'max', \n",
    "#                               cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "# #             pm1 = ax.pcolormesh(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "# #                                 norm = mplc.LogNorm(vmin = 0.1, vmax = 40), \n",
    "# #                                 cmap = cm.jet, transform = data_proj, zorder = 1) \n",
    "\n",
    "#             #Gridlines\n",
    "#             gl = ax.gridlines(crs = ccrs.PlateCarree(), draw_labels = True, \n",
    "#                               linewidth = 0.5, color = 'gray', alpha = 0.5, linestyle = '--', zorder = 2)\n",
    "#             gl.top_labels = False\n",
    "#             gl.right_labels = False\n",
    "\n",
    "#             #plot ERA5 streamlines\n",
    "#             ax.streamplot(ds.longitude, ds.latitude, uwnd[0].values, vwnd[0].values,\n",
    "#                           color = 'k', linewidth = 0.6, density = 1.0, transform = data_proj, zorder = 3)\n",
    "\n",
    "#             #plot flight track\n",
    "#             ax.plot(flight_lon, flight_lat, color = 'white', linewidth = 1.5, zorder = 4)            \n",
    "            \n",
    "#             #plot near-storm dropsonde locations for the given flight \n",
    "#                 #if the dropsonde was deployed within 30 minutes (1-hr total range) of the given hour\n",
    "#                     #NOTE: Dropsondes with no wind data don't have GPS data either (5 of them total)\n",
    "#             for sonde in drop_coords_and_time:\n",
    "#                 if (sonde[2][:2] == hour_prior and int(sonde[2][2:4]) >= 30) or (sonde[2][:2] == hr2 and int(sonde[2][2:4]) < 30):\n",
    "#                     #ax.scatter(sonde[0], sonde[1], marker = f'${sonde[2]}$', color = 'b', s = 300)\n",
    "#                     ax.scatter(sonde[0], sonde[1], marker = '*', color = 'k', zorder = 5, s = 300)\n",
    "\n",
    "#             #same as above, but labeling the dropsondes by the order that they appear in the\n",
    "#                 #Dropsonde_Metric_Calculations.csv, NOT IN CHRONOLOGICAL ORDER!!!\n",
    "#             #for z, sonde in enumerate(drop_coords_and_time):\n",
    "#                 #ax.scatter(sonde[0], sonde[1], marker = f'${z + 1}$', color = 'b', s = 120, zorder = 5) \n",
    "                \n",
    "#             #plotting the colorbars\n",
    "#             #cbar0 = group_fig.colorbar(pm0, ax = ax, orientation = 'vertical', shrink = 0.75, pad = 0.25)\n",
    "#             #cbar0.set_label('TPW [mm]')\n",
    "#             #cbar0.ax.yaxis.set_ticks_position('left')\n",
    "#             #cbar0.ax.yaxis.set_label_position('left')\n",
    "            \n",
    "#             #this works with GeoAxes (i.e., Cartopy's map projections)\n",
    "#             if ii == len(pressures_to_plot_stream) - 1:\n",
    "                \n",
    "# #                 #MIMIC TPW colorbar\n",
    "# #                 ticks_tpw = np.arange(0, 70.5, 10, dtype = int)\n",
    "# #                 #cax = group_fig.add_axes([ax.get_position().x1+0.05, ax.get_position().y0, 0.02, ax.get_position().height])\n",
    "# #                 cax0 = group_fig.add_axes([ax.get_position().x1 + 0.05, ax.get_position().y0, 0.02, 0.75])\n",
    "# #                 cbar0 = group_fig.colorbar(pm0, cax = cax0, ticks = ticks_tpw)\n",
    "# #                 cbar0.set_label('TPW [mm]')\n",
    "# #                 cbar0.ax.set_yticklabels(list(map(str, list(ticks_tpw))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "# #                 cbar0.ax.yaxis.set_ticks_position('left')\n",
    "# #                 cbar0.ax.yaxis.set_label_position('left')\n",
    "\n",
    "#                 #ERA5 RH colorbar\n",
    "#                 ticks_rh = np.arange(0, 100.5, 10, dtype = int)\n",
    "#                 #cax = group_fig.add_axes([ax.get_position().x1+0.05, ax.get_position().y0, 0.02, ax.get_position().height])\n",
    "#                 cax0 = group_fig.add_axes([ax.get_position().x1 + 0.05, ax.get_position().y0, 0.02, 0.75])\n",
    "#                 cbar0 = group_fig.colorbar(pm0, cax = cax0, ticks = ticks_rh)\n",
    "#                 cbar0.set_label('Relative Humidity [%]')\n",
    "#                 cbar0.ax.set_yticklabels(list(map(str, list(ticks_rh))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "#                 cbar0.ax.yaxis.set_ticks_position('left')\n",
    "#                 cbar0.ax.yaxis.set_label_position('left')\n",
    "                \n",
    "#                 #IMERG colorbar\n",
    "#                 ticks_imerg = np.array([0.1, 1, 5, 10, 20, 40], dtype = float)\n",
    "#                 cax1 = group_fig.add_axes([ax.get_position().x1 + 0.05, ax.get_position().y0, 0.02, 0.75])\n",
    "#                 cbar1 = group_fig.colorbar(pm1, cax = cax1, ticks = ticks_imerg)\n",
    "#                 cbar1.set_label('IMERG [mm hr$\\\\bf{^{-1}}$]')\n",
    "#                 cbar1.ax.set_yticklabels(list(map(str, list(ticks_imerg))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "#                 cbar1.ax.yaxis.set_ticks_position('right')\n",
    "#                 cbar1.ax.yaxis.set_label_position('right')\n",
    "                \n",
    "#         ds_tpw.close()\n",
    "#         ds_imerg.close()                \n",
    "                \n",
    "#         #plt.tight_layout()\n",
    "#         #plt.subplots_adjust(wspace = 0.1)\n",
    "\n",
    "#         #save the figure\n",
    "#         plot_save_name = f'ERA5_streamlines_RH_{hr2}UTC.png'\n",
    "#         plt.savefig(os.path.join(day_folder, plot_save_name), bbox_inches = 'tight')\n",
    "#         #plt.show()  #plt.show() must come after plt.savefig() in order for the image to save properly\n",
    "#         #plt.clf()   #supposedly speeds things up? According to: https://www.youtube.com/watch?v=jGVIZbi9uMY\n",
    "#         plt.close()\n",
    "#         plt.clf()    #if placing this after plt.close(), may release memory related to the figure (https://stackoverflow.com/questions/741877/how-do-i-tell-matplotlib-that-i-am-done-with-a-plot)\n",
    "\n",
    "#         ##decrease file size of the image by 66% without noticeable image effects (if using Matplotlib)\n",
    "#         ##(good to use if you're producing a lot of images, see https://www.youtube.com/watch?v=fzhAseXp5B4)\n",
    "#         im = Image.open(os.path.join(day_folder, plot_save_name))\n",
    "\n",
    "#         try:\n",
    "#             im2 = im.convert('P', palette = Image.Palette.ADAPTIVE)\n",
    "#         except:\n",
    "#             #use this for older version of PIL/Pillow if the above line doesn't work, \n",
    "#             #though this line will have isolated, extremely minor image effects due to \n",
    "#             #only using 256 colors instead of the 3-element RGB scale\n",
    "#             im2 = im.convert('P')\n",
    "\n",
    "#         im2.save(os.path.join(day_folder, plot_save_name))\n",
    "#         im.close()\n",
    "#         im2.close()\n",
    "\n",
    "#     ds.close()\n",
    "    \n",
    "#     print (file_date + ' streamline plots complete!\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73ee77",
   "metadata": {},
   "source": [
    "#### Convergence at Various Pressure Levels with flight track and dropsondes overlaid for each desired flight and time ranges in case_dict_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b88141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #set some baseline plot displays\n",
    "\n",
    "# #matplotlib.rcParams['axes.facecolor'] = [0.9,0.9,0.9]\n",
    "# matplotlib.rcParams['axes.labelsize'] = 12\n",
    "# matplotlib.rcParams['axes.titlesize'] = 12\n",
    "# matplotlib.rcParams['axes.labelweight'] = 'bold'\n",
    "# matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "# matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "# matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "# matplotlib.rcParams['legend.fontsize'] = 16\n",
    "# #matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "# #matplotlib.rcParams['axes.facecolor'] = 'w'\n",
    "# matplotlib.rcParams['font.family'] = 'arial'\n",
    "# matplotlib.rcParams['hatch.linewidth'] = 0.3\n",
    "\n",
    "# #file_date is the date on which the desired flight took place\n",
    "# #utc_hours_to_plot is the desired UTC hours to be plotted for the given flight (e.g., convective case hours/time range)\n",
    "# for file_date, utc_hours_to_plot in case_dict_conv.items():\n",
    "\n",
    "#     print (file_date + ' convergence plots in progress...')\n",
    "    \n",
    "#     ###get locations of the dropsonde/Navigation/ERA5 folder and read the appropriate files in\n",
    "#     day_folder = os.path.join(os.getcwd(), file_date)\n",
    "\n",
    "#     #dropsonde data\n",
    "#     drop_csv_path = os.path.join(day_folder, 'final_dropsonde_' + file_date + '.csv')\n",
    "#     drop_csv = pd.read_csv(drop_csv_path)\n",
    "\n",
    "#     if file_date[:4] == '2017':\n",
    "#         campaign = 'CPEX'\n",
    "#         drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "#     elif file_date[:4] == '2021':\n",
    "#         campaign = 'CPEXAW'\n",
    "#         drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "#     elif file_date[:4] == '2022':\n",
    "#         campaign = 'CPEXCV'\n",
    "#         drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations_CPEXCV.csv')\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "#     #ERA5 data\n",
    "#     era5_folder = os.path.join(os.getcwd(), 'ERA5_Reanalysis_Data')\n",
    "#     era5_path = os.path.join(era5_folder, campaign + '_ERA5_Reanalysis_Hourly_Pressure.nc')\n",
    "#     ds = xr.open_dataset(era5_path)\n",
    "\n",
    "#     #Navigation data\n",
    "#     nav_folder = os.path.join(day_folder, 'Nav_files')\n",
    "\n",
    "#     for x in os.listdir(nav_folder):\n",
    "#         if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "#             os.remove(os.path.join(nav_folder, x))\n",
    "\n",
    "#     nav_ict_path = os.path.join(nav_folder, os.listdir(nav_folder)[0])  #only one nav file per flight\n",
    "\n",
    "#     if campaign != 'CPEX':  #campaign either CPEXAW or CPEXCV\n",
    "\n",
    "#         nav_ict = icartt.Dataset(nav_ict_path)    #open the ict file with icartt\n",
    "#         flight_lat = nav_ict.data[\"Latitude\"]     #nav latitude, just a normal 1-D array\n",
    "#         flight_lon = nav_ict.data[\"Longitude\"]    #nav longitude, just a normal 1-D array\n",
    "\n",
    "#     else:  #for CPEX navigation files, open the CSV file with pandas\n",
    "#            #(Navigation files for CPEX (2017) are originally .kmz not .ict,\n",
    "#            #so I converted them to CSV for free using https://www.gpsvisualizer.com/convert_input\n",
    "\n",
    "#         nav_ict = pd.read_csv(nav_ict_path)       #open the ict file with pandas instead\n",
    "#         flight_lat = nav_ict[\"latitude\"].values   #nav latitude, just a normal 1-D array\n",
    "#         flight_lon = nav_ict[\"longitude\"].values  #nav longitude, just a normal 1-D array    \n",
    "\n",
    "#     #flight track lat/lon extent [West,East,South,North] for plotting, giving an XX degree buffer around the flight track   \n",
    "#     campaign_extent = [flight_lon.min() - 2.5, flight_lon.max() + 2.5, flight_lat.min() - 2.5, flight_lat.max() + 2.5]\n",
    "\n",
    "\n",
    "#     ###calculate each near-storm dropsonde's mean lat/lon and add the sonde's time and mean lat/lon to a list to be plotted\n",
    "\n",
    "#     drop_coords_and_time = []   #format: longitude, latitude, time (HHSS)\n",
    "\n",
    "#     df_drop = pd.read_csv(drop_metric_filepath)\n",
    "#     df_drop_use = df_drop[df_drop['Date'] == int(file_date)].copy()\n",
    "\n",
    "#     for x in range(len(df_drop_use)):\n",
    "#         date = str(df_drop_use['Date'].iloc[x])\n",
    "#         time = str(df_drop_use['Time'].iloc[x]).zfill(6)\n",
    "#         sonde_datetime = date[:4] + '-' + date[4:6] + '-' + date[6:] + ' ' + time[:2] + ':' + time[2:4] + ':' + time[4:]\n",
    "\n",
    "#         drop_csv_use = drop_csv[drop_csv['Time [UTC]'] == sonde_datetime].copy()\n",
    "#         drop_mean_lon = drop_csv_use['Longitude [deg]'].mean()\n",
    "#         drop_mean_lat = drop_csv_use['Latitude [deg]'].mean()\n",
    "\n",
    "#         sonde_info = [drop_mean_lon, drop_mean_lat, time[:4]]\n",
    "#         drop_coords_and_time.append(sonde_info)\n",
    "\n",
    "        \n",
    "#     ###create an XX-panel plot of convergence at XX-different pressure levels \n",
    "#         ###for each desired hour of the given day\n",
    "\n",
    "#     half_pres_levs = math.ceil(len(pressures_to_plot_conv) / 2)   #to determine size of figure and number of subplots to generate (rounded up to the nearest multiple of 2)\n",
    "\n",
    "#     for hr in utc_hours_to_plot:\n",
    "        \n",
    "#         hr2 = str(hr).zfill(2)\n",
    "#         hour_prior = str(hr - 1).zfill(2)\n",
    "\n",
    "#         #MIMIC TPW data\n",
    "#             ##https://bin.ssec.wisc.edu/pub/mtpw2/data/\n",
    "#         tpw_folder = os.path.join(day_folder, 'MIMIC_TPW_files')\n",
    "#         tpw_path = os.path.join(tpw_folder, 'comp' + file_date + '.' + hr2 + '0000.nc')\n",
    "#         ds_tpw = xr.open_dataset(tpw_path)\n",
    "\n",
    "#         #GPM IMERG data (see IMERG.ipynb for more how to more generally download and plot IMERG data)\n",
    "#            ##https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Read%20IMERG%20Data%20Using%20Python\n",
    "#            ##https://disc.gsfc.nasa.gov/datasets?keywords=imerg&page=1\n",
    "#            #0.1 x 0.1 gridded data, half-hourly means, using the half hour BEFORE the desired hour\n",
    "#         imerg_folder = os.path.join(day_folder, 'IMERG_files')\n",
    "        \n",
    "#         for x in os.listdir(imerg_folder):\n",
    "#             if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "#                 os.remove(os.path.join(imerg_folder, x))\n",
    "                \n",
    "#             #minutes and seconds automatically revert to zero (hour = 0, seconds = 0) for '%Y%m%d%H'\n",
    "#             elif (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(seconds = 1), '%H%M%S') in x) and (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(minutes = 30), '%H%M%S') in x):\n",
    "#                 imerg_file = x\n",
    "#                 break\n",
    "#             else:\n",
    "#                 imerg_file = 'Could not find the desired IMERG file'\n",
    "        \n",
    "#         #confirm that the IMERG file is from the correct day (if hr2 == '00', then this will be the previous day)\n",
    "#         assert (file_date in imerg_file) or (hr2 == '00'), 'IMERG file not from the correct day'\n",
    "        \n",
    "#         imerg_path = os.path.join(imerg_folder, imerg_file)\n",
    "#         ds_imerg = h5py.File(imerg_path, 'r')\n",
    "        \n",
    "#         imerg_lons = ds_imerg['Grid/lon'][:]   #Longitude Shape: (3600,)\n",
    "#         imerg_lats = ds_imerg['Grid/lat'][:]   #Latitude Shape: (1800,)\n",
    "#         imerg_lons, imerg_lats = np.meshgrid(imerg_lons, imerg_lats)  #Long and lat grid shape: (1800, 3600) \n",
    "        \n",
    "#         imerg_precip = ds_imerg['Grid/precipitation'][0][:][:]  #Original Precip Shape: (1, 3600, 1800) = (time, lon, lat)\n",
    "#         imerg_precip = np.transpose(imerg_precip)               #New Precip Shape after transpose: (1800, 3600)\n",
    "        \n",
    "#         #mask blank data\n",
    "#         imerg_precip_masked = np.ma.masked_where(imerg_precip < 0, imerg_precip)  #masks blank and bad data first (if blank data is -999 instead of NaN)\n",
    "#         imerg_precip_masked = np.ma.masked_where(np.isnan(imerg_precip_masked), imerg_precip_masked)  #masks NaN values (not masked in previous line)\n",
    "        \n",
    "#         data_proj = ccrs.PlateCarree()\n",
    "\n",
    "#         group_fig = plt.figure(figsize = (6 * half_pres_levs, 6 * half_pres_levs))\n",
    "        \n",
    "#         for ii, pres_lev in enumerate(pressures_to_plot_conv):\n",
    "#             ax = group_fig.add_subplot(2, half_pres_levs, ii+1, projection = data_proj)\n",
    "\n",
    "#             conv = ds.d.sel(time = file_date).sel(level = pres_lev) * -1   #convergence of the wind (1/s)\n",
    "#             conv = conv.sel(time = conv.time.dt.hour.isin(hr)) * 10**5     #convergence of the wind (times 10**5 1/s)\n",
    "            \n",
    "#             rh = ds.r.sel(time = file_date).sel(level = pressures_to_plot_RH[ii])    #relative humidity (%)\n",
    "#             rh = rh.sel(time = rh.time.dt.hour.isin(hr))                             #relative humidity (%)\n",
    "\n",
    "#             ##Smoothing (source: Hannah Zanowski) --> not recommended, see top of document\n",
    "#                 ##Metpy smooth_n_point (data to be smoothed, number of points to use in smoothing (5 to 9 are valid), and number of times the smoother is applied)\n",
    "#                     ##see https://unidata.github.io/MetPy/latest/api/generated/metpy.calc.smooth_n_point.html for more info\n",
    "#             #conv_smoothed = mpcalc.smooth_n_point(conv,9,1)\n",
    "    \n",
    "#             #ax.set_title('MIMIC TPW, GPM IMERG, and \\n%i hPa ERA5 Convergence ($\\\\bf{10^{-5} s^{-1}}$) (%s, %s UTC)' % (pres_lev, file_date, hr2))\n",
    "#             ax.set_title('ERA5 %i hPa RH, GPM IMERG, and \\nERA5 %i hPa Convergence ($\\\\bf{10^{-5} s^{-1}}$) (%s, %s UTC)' % (pressures_to_plot_RH[ii], pres_lev, file_date, hr2))\n",
    "#             ax.set_extent(campaign_extent, ccrs.PlateCarree()) #lat/lon bounds are [West,East,South,North]\n",
    "\n",
    "#             # Add land, coastlines, and borders\n",
    "#             #ax.add_feature(cfeature.LAND, facecolor='0.8')\n",
    "#             ax.coastlines(ls = '-', linewidth = 0.5, color = 'gray')\n",
    "\n",
    "# #             #plot MIMIC TPW\n",
    "# #             tpw_levels = np.arange(0, 70.5, 2)\n",
    "# #             pm0 = ax.contourf(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, levels = tpw_levels,\n",
    "# #                               extend = 'max', cmap = cm.jet, transform = data_proj)\n",
    "# # #             pm0 = ax.pcolormesh(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, vmin = 0, vmax = 70,\n",
    "# # #                                 cmap = cm.jet, transform = data_proj, zorder = 0)\n",
    "\n",
    "#             #plot ERA5 RH\n",
    "#             tpw_levels = np.arange(0, 100.1, 2)  #actually RH levels, but keeping the tpw_levels name because we use it elsewhere\n",
    "#             pm0 = ax.contourf(ds.longitude, ds.latitude, rh[0].values, levels = tpw_levels,\n",
    "#                               extend = 'max', cmap = cm.jet, transform = data_proj, alpha = 0.6)\n",
    "#         #             pm0 = ax.pcolormesh(ds.longitude, ds.latitude, rh[0].values, vmin = 0, vmax = 70,\n",
    "#         #                                 cmap = cm.jet, transform = data_proj, zorder = 0)\n",
    "    \n",
    "#             #plot IMERG Rain Rate\n",
    "#             pm1 = ax.contourf(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "#                               levels = np.logspace(np.log10(0.1), np.log10(40), num = len(tpw_levels)), \n",
    "#                               norm = 'log', extend = 'max', \n",
    "#                               cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "# #             pm1 = ax.pcolormesh(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "# #                                 norm = mplc.LogNorm(vmin = 0.1, vmax = 40), \n",
    "# #                                 cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "            \n",
    "#             #gridlines\n",
    "#             gl = ax.gridlines(crs = ccrs.PlateCarree(), draw_labels = True, \n",
    "#                               linewidth = 0.5, color = 'gray', alpha = 0.5, linestyle = '--', zorder = 2)\n",
    "#             gl.top_labels = False\n",
    "#             gl.right_labels = False\n",
    "\n",
    "#             #plot ERA5 convergence\n",
    "#             ax.contour(ds.longitude, ds.latitude, conv[0].values, levels = np.arange(1, 201.1, 2),\n",
    "#                        colors = 'k', linewidths = 0.6, transform = data_proj, zorder = 3)            \n",
    "            \n",
    "#             #plot flight track\n",
    "#             ax.plot(flight_lon, flight_lat, color = 'white', linewidth = 1.5, zorder = 4)\n",
    "                \n",
    "#             #plot near-storm dropsonde locations for the given flight \n",
    "#                 #if the dropsonde was deployed within 30 minutes (1-hr total range) of the given hour\n",
    "#                     #NOTE: Dropsondes with no wind data don't have GPS data either (5 of them total)\n",
    "#             for sonde in drop_coords_and_time:\n",
    "#                 if (sonde[2][:2] == hour_prior and int(sonde[2][2:4]) >= 30) or (sonde[2][:2] == hr2 and int(sonde[2][2:4]) < 30):\n",
    "#                     #ax.scatter(sonde[0], sonde[1], marker = f'${sonde[2]}$', color = 'b', s = 300)\n",
    "#                     ax.scatter(sonde[0], sonde[1], marker = '*', color = 'k', s = 80, zorder = 5)\n",
    "                \n",
    "#             #same as above, but labeling the dropsondes by the order that they appear in the\n",
    "#                 #Dropsonde_Metric_Calculations.csv, NOT IN CHRONOLOGICAL ORDER!!!\n",
    "#             #for z, sonde in enumerate(drop_coords_and_time):\n",
    "#                 #ax.scatter(sonde[0], sonde[1], marker = f'${z + 1}$', color = 'b', s = 120, zorder = 5)\n",
    "\n",
    "#             #plotting the colorbars\n",
    "#             #cbar0 = group_fig.colorbar(pm0, ax = ax, orientation = 'vertical', shrink = 0.75, pad = 0.25)\n",
    "#             #cbar0.set_label('TPW [mm]')\n",
    "#             #cbar0.ax.yaxis.set_ticks_position('left')\n",
    "#             #cbar0.ax.yaxis.set_label_position('left')\n",
    "            \n",
    "#             #this works with GeoAxes (i.e., Cartopy's map projections)\n",
    "#             if ii == len(pressures_to_plot_conv) - 1:\n",
    "                \n",
    "# #                 #MIMIC TPW colorbar\n",
    "# #                 ticks_tpw = np.arange(0, 70.5, 10, dtype = int)\n",
    "# #                 #cax = group_fig.add_axes([ax.get_position().x1+0.05, ax.get_position().y0, 0.02, ax.get_position().height])\n",
    "# #                 cax0 = group_fig.add_axes([ax.get_position().x1 + 0.1, ax.get_position().y0, 0.02, 0.75])\n",
    "# #                 cbar0 = group_fig.colorbar(pm0, cax = cax0, ticks = ticks_tpw)\n",
    "# #                 cbar0.set_label('TPW [mm]')\n",
    "# #                 cbar0.ax.set_yticklabels(list(map(str, list(ticks_tpw))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "# #                 cbar0.ax.yaxis.set_ticks_position('left')\n",
    "# #                 cbar0.ax.yaxis.set_label_position('left')\n",
    "\n",
    "#                 #ERA5 RH colorbar\n",
    "#                 ticks_rh = np.arange(0, 100.5, 10, dtype = int)\n",
    "#                 #cax = group_fig.add_axes([ax.get_position().x1+0.05, ax.get_position().y0, 0.02, ax.get_position().height])\n",
    "#                 cax0 = group_fig.add_axes([ax.get_position().x1 + 0.1, ax.get_position().y0, 0.02, 0.75])\n",
    "#                 cbar0 = group_fig.colorbar(pm0, cax = cax0, ticks = ticks_rh)\n",
    "#                 cbar0.set_label('Relative Humidity [%]')\n",
    "#                 cbar0.ax.set_yticklabels(list(map(str, list(ticks_rh))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "#                 cbar0.ax.yaxis.set_ticks_position('left')\n",
    "#                 cbar0.ax.yaxis.set_label_position('left')\n",
    "                \n",
    "#                 #IMERG colorbar\n",
    "#                 ticks_imerg = np.array([0.1, 1, 5, 10, 20, 40], dtype = float)\n",
    "#                 cax1 = group_fig.add_axes([ax.get_position().x1 + 0.1, ax.get_position().y0, 0.02, 0.75])\n",
    "#                 cbar1 = group_fig.colorbar(pm1, cax = cax1, ticks = ticks_imerg)\n",
    "#                 cbar1.set_label('IMERG [mm hr$\\\\bf{^{-1}}$]')\n",
    "#                 cbar1.ax.set_yticklabels(list(map(str, list(ticks_imerg))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "#                 cbar1.ax.yaxis.set_ticks_position('right')\n",
    "#                 cbar1.ax.yaxis.set_label_position('right')\n",
    "                \n",
    "#         ds_tpw.close()\n",
    "#         ds_imerg.close()\n",
    "            \n",
    "#         #plt.tight_layout()\n",
    "#         plt.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "#         #save the figure\n",
    "#         plot_save_name = f'ERA5_convergence_midRH_{hr2}UTC.png'\n",
    "#         plt.savefig(os.path.join(day_folder, plot_save_name), bbox_inches = 'tight')\n",
    "#         #plt.show()  #plt.show() must come after plt.savefig() in order for the image to save properly\n",
    "#         #plt.clf()   #supposedly speeds things up? According to: https://www.youtube.com/watch?v=jGVIZbi9uMY\n",
    "#         plt.close()\n",
    "#         plt.clf()    #if placing this after plt.close(), may release memory related to the figure (https://stackoverflow.com/questions/741877/how-do-i-tell-matplotlib-that-i-am-done-with-a-plot)\n",
    "\n",
    "#         ##decrease file size of the image by 66% without noticeable image effects (if using Matplotlib)\n",
    "#         ##(good to use if you're producing a lot of images, see https://www.youtube.com/watch?v=fzhAseXp5B4)\n",
    "#         im = Image.open(os.path.join(day_folder, plot_save_name))\n",
    "\n",
    "#         try:\n",
    "#             im2 = im.convert('P', palette = Image.Palette.ADAPTIVE)\n",
    "#         except:\n",
    "#             #use this for older version of PIL/Pillow if the above line doesn't work, \n",
    "#             #though this line will have isolated, extremely minor image effects due to \n",
    "#             #only using 256 colors instead of the 3-element RGB scale\n",
    "#             im2 = im.convert('P')\n",
    "\n",
    "#         im2.save(os.path.join(day_folder, plot_save_name))\n",
    "#         im.close()\n",
    "#         im2.close()\n",
    "\n",
    "#     ds.close()\n",
    "    \n",
    "#     print (file_date + ' convergence plots complete!\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42814232",
   "metadata": {},
   "source": [
    "#### Figure 11 for AGU Paper (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52462da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#FIGURE 11 FOR AGU PAPER (2023)\n",
    "\n",
    "case_dict_agu = {0: ['20170611', 'Case 13', 19, [-95, -80, 20, 28]], \n",
    "                 1: ['20210824', 'Case 16', 19, [-75, -60, 10, 18]]}  #flight track lat/lon extent [West,East,South,North]\n",
    "conv_pres = 975  #hPa; pressure level to plot ERA5 convergence for\n",
    "\n",
    "drop_metric_cases1316_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations_OnlyCases13and16.csv')\n",
    "df_drop_cases1316 = pd.read_csv(drop_metric_cases1316_filepath)\n",
    "\n",
    "#set some baseline plot displays\n",
    "\n",
    "#matplotlib.rcParams['axes.facecolor'] = [0.9,0.9,0.9]\n",
    "matplotlib.rcParams['axes.labelsize'] = 16\n",
    "matplotlib.rcParams['axes.titlesize'] = 19\n",
    "matplotlib.rcParams['axes.labelweight'] = 'bold'\n",
    "matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "matplotlib.rcParams['xtick.labelsize'] = 16\n",
    "matplotlib.rcParams['ytick.labelsize'] = 16\n",
    "matplotlib.rcParams['legend.fontsize'] = 16\n",
    "#matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "#matplotlib.rcParams['axes.facecolor'] = 'w'\n",
    "matplotlib.rcParams['font.family'] = 'arial'\n",
    "matplotlib.rcParams['hatch.linewidth'] = 0.3\n",
    "\n",
    "data_proj = ccrs.PlateCarree()\n",
    "group_fig = plt.figure(figsize = (30,15))\n",
    "\n",
    "for key, case_info in case_dict_agu.items():\n",
    "    \n",
    "    file_date = case_info[0]\n",
    "    case_num = case_info[1]   \n",
    "    hr = case_info[2]\n",
    "    campaign_extent = case_info[3]\n",
    "\n",
    "    print (file_date + ' convergence plots in progress...')\n",
    "    \n",
    "    ###get locations of the dropsonde/Navigation/ERA5 folder and read the appropriate files in\n",
    "    day_folder = os.path.join(os.getcwd(), file_date)\n",
    "\n",
    "    #dropsonde data\n",
    "    drop_csv_path = os.path.join(day_folder, 'final_dropsonde_' + file_date + '.csv')\n",
    "    drop_csv = pd.read_csv(drop_csv_path)\n",
    "\n",
    "    if file_date[:4] == '2017':\n",
    "        campaign = 'CPEX'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "    elif file_date[:4] == '2021':\n",
    "        campaign = 'CPEXAW'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "    elif file_date[:4] == '2022':\n",
    "        campaign = 'CPEXCV'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations_CPEXCV.csv')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #ERA5 data\n",
    "    era5_folder = os.path.join(os.getcwd(), 'ERA5_Reanalysis_Data')\n",
    "    era5_path = os.path.join(era5_folder, campaign + '_ERA5_Reanalysis_Hourly_Pressure.nc')\n",
    "    ds = xr.open_dataset(era5_path)\n",
    "\n",
    "    #Navigation data\n",
    "    nav_folder = os.path.join(day_folder, 'Nav_files')\n",
    "\n",
    "    for x in os.listdir(nav_folder):\n",
    "        if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "            os.remove(os.path.join(nav_folder, x))\n",
    "\n",
    "    nav_ict_path = os.path.join(nav_folder, os.listdir(nav_folder)[0])  #only one nav file per flight\n",
    "\n",
    "    if campaign != 'CPEX':  #campaign either CPEXAW or CPEXCV\n",
    "\n",
    "        nav_ict = icartt.Dataset(nav_ict_path)    #open the ict file with icartt\n",
    "        flight_lat = nav_ict.data[\"Latitude\"]     #nav latitude, just a normal 1-D array\n",
    "        flight_lon = nav_ict.data[\"Longitude\"]    #nav longitude, just a normal 1-D array\n",
    "\n",
    "    else:  #for CPEX navigation files, open the CSV file with pandas\n",
    "           #(Navigation files for CPEX (2017) are originally .kmz not .ict,\n",
    "           #so I converted them to CSV for free using https://www.gpsvisualizer.com/convert_input\n",
    "\n",
    "        nav_ict = pd.read_csv(nav_ict_path)       #open the ict file with pandas instead\n",
    "        flight_lat = nav_ict[\"latitude\"].values   #nav latitude, just a normal 1-D array\n",
    "        flight_lon = nav_ict[\"longitude\"].values  #nav longitude, just a normal 1-D array    \n",
    "\n",
    "\n",
    "    ###calculate each near-storm dropsonde's mean lat/lon and add the sonde's time and mean lat/lon to a list to be plotted\n",
    "\n",
    "    drop_coords_and_time = []   #format: longitude, latitude, time (HHSS)\n",
    "\n",
    "    df_drop = pd.read_csv(drop_metric_filepath)\n",
    "    df_drop_use = df_drop[df_drop['Date'] == int(file_date)].copy()\n",
    "\n",
    "    for x in range(len(df_drop_use)):\n",
    "        date = str(df_drop_use['Date'].iloc[x])\n",
    "        time = str(df_drop_use['Time'].iloc[x]).zfill(6)\n",
    "        sonde_datetime = date[:4] + '-' + date[4:6] + '-' + date[6:] + ' ' + time[:2] + ':' + time[2:4] + ':' + time[4:]\n",
    "\n",
    "        drop_csv_use = drop_csv[drop_csv['Time [UTC]'] == sonde_datetime].copy()\n",
    "        drop_mean_lon = drop_csv_use['Longitude [deg]'].mean()\n",
    "        drop_mean_lat = drop_csv_use['Latitude [deg]'].mean()\n",
    "\n",
    "        sonde_info = [drop_mean_lon, drop_mean_lat, time[:4], date, time]\n",
    "        drop_coords_and_time.append(sonde_info)\n",
    "        \n",
    "    hr2 = str(hr).zfill(2)\n",
    "\n",
    "    #MIMIC TPW data\n",
    "        ##https://bin.ssec.wisc.edu/pub/mtpw2/data/\n",
    "    tpw_folder = os.path.join(day_folder, 'MIMIC_TPW_files')\n",
    "    tpw_path = os.path.join(tpw_folder, 'comp' + file_date + '.' + hr2 + '0000.nc')\n",
    "    ds_tpw = xr.open_dataset(tpw_path)\n",
    "\n",
    "    #GPM IMERG data (see IMERG.ipynb for more how to more generally download and plot IMERG data)\n",
    "        ##https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Read%20IMERG%20Data%20Using%20Python\n",
    "        ##https://disc.gsfc.nasa.gov/datasets?keywords=imerg&page=1\n",
    "        #0.1 x 0.1 gridded data, half-hourly means, using the half hour BEFORE the desired hour\n",
    "    imerg_folder = os.path.join(day_folder, 'IMERG_files')\n",
    "\n",
    "    for x in os.listdir(imerg_folder):\n",
    "        if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "            os.remove(os.path.join(imerg_folder, x))\n",
    "\n",
    "        #minutes and seconds automatically revert to zero (hour = 0, seconds = 0) for '%Y%m%d%H'\n",
    "        elif (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(seconds = 1), '%H%M%S') in x) and (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(minutes = 30), '%H%M%S') in x):\n",
    "            imerg_file = x\n",
    "            break\n",
    "        else:\n",
    "            imerg_file = 'Could not find the desired IMERG file'\n",
    "\n",
    "    #confirm that the IMERG file is from the correct day (if hr2 == '00', then this will be the previous day)\n",
    "    assert (file_date in imerg_file) or (hr2 == '00'), 'IMERG file not from the correct day'\n",
    "\n",
    "    imerg_path = os.path.join(imerg_folder, imerg_file)\n",
    "    ds_imerg = h5py.File(imerg_path, 'r')\n",
    "\n",
    "    imerg_lons = ds_imerg['Grid/lon'][:]   #Longitude Shape: (3600,)\n",
    "    imerg_lats = ds_imerg['Grid/lat'][:]   #Latitude Shape: (1800,)\n",
    "    imerg_lons, imerg_lats = np.meshgrid(imerg_lons, imerg_lats)  #Long and lat grid shape: (1800, 3600) \n",
    "\n",
    "    imerg_precip = ds_imerg['Grid/precipitation'][0][:][:]  #Original Precip Shape: (1, 3600, 1800) = (time, lon, lat)\n",
    "    imerg_precip = np.transpose(imerg_precip)               #New Precip Shape after transpose: (1800, 3600)\n",
    "\n",
    "    #mask blank data\n",
    "    imerg_precip_masked = np.ma.masked_where(imerg_precip < 0, imerg_precip)  #masks blank and bad data first (if blank data is -999 instead of NaN)\n",
    "    imerg_precip_masked = np.ma.masked_where(np.isnan(imerg_precip_masked), imerg_precip_masked)  #masks NaN values (not masked in previous line)\n",
    "\n",
    "    #creat the plot\n",
    "    ax = group_fig.add_subplot(2, 1, key+1, projection = data_proj)\n",
    "\n",
    "    conv = ds.d.sel(time = file_date).sel(level = conv_pres) * -1   #convergence of the wind (1/s)\n",
    "    conv = conv.sel(time = conv.time.dt.hour.isin(hr)) * 10**5      #convergence of the wind (times 10**5 1/s)\n",
    "\n",
    "    ##Smoothing (source: Hannah Zanowski) --> not recommended, see top of document\n",
    "        ##Metpy smooth_n_point (data to be smoothed, number of points to use in smoothing (5 to 9 are valid), and number of times the smoother is applied)\n",
    "            ##see https://unidata.github.io/MetPy/latest/api/generated/metpy.calc.smooth_n_point.html for more info\n",
    "    #conv_smoothed = mpcalc.smooth_n_point(conv,9,1)\n",
    "\n",
    "    ax.set_title('%s MIMIC TPW, GPM IMERG, and ERA5 %i hPa Convergence (%s UTC)' % (case_num, conv_pres, hr2))\n",
    "    ax.set_extent(campaign_extent, ccrs.PlateCarree()) #lat/lon bounds are [West,East,South,North]\n",
    "\n",
    "    # Add land, coastlines, and borders\n",
    "    #ax.add_feature(cfeature.LAND, facecolor='0.8')\n",
    "    ax.coastlines(ls = '-', linewidth = 0.5, color = 'gray')\n",
    "\n",
    "    #plot MIMIC TPW\n",
    "    tpw_levels = np.arange(0, 70.5, 2)\n",
    "    pm0 = ax.contourf(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, levels = tpw_levels,\n",
    "                      extend = 'max', cmap = cm.jet, transform = data_proj)\n",
    "#             pm0 = ax.pcolormesh(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, vmin = 0, vmax = 70,\n",
    "#                                 cmap = cm.jet, transform = data_proj, zorder = 0)\n",
    "\n",
    "    #plot IMERG Rain Rate\n",
    "    pm1 = ax.contourf(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "                      levels = np.logspace(np.log10(0.1), np.log10(40), num = len(tpw_levels)), \n",
    "                      norm = 'log', extend = 'max', \n",
    "                      cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "#             pm1 = ax.pcolormesh(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "#                                 norm = mplc.LogNorm(vmin = 0.1, vmax = 40), \n",
    "#                                 cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "\n",
    "    #gridlines\n",
    "    gl = ax.gridlines(crs = ccrs.PlateCarree(), draw_labels = True, linewidth = 0.5, \n",
    "                      color = 'gray', alpha = 0.5, linestyle = '--', zorder = 2)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {'size':16, 'color':'black'}\n",
    "    gl.ylabel_style = {'size':16, 'color':'black'}\n",
    "    \n",
    "    level_array = np.arange(1, 201.1, 2)\n",
    "    linewidth_array = np.full_like(level_array, 0.6)\n",
    "    linewidth_array[3:] = 2.5   #values 7 x 10^-5 s^-1 and greater will have thicker contours\n",
    "\n",
    "    #plot ERA5 convergence\n",
    "    ax.contour(ds.longitude, ds.latitude, conv[0].values, levels = level_array,\n",
    "               colors = 'k', linewidths = linewidth_array, transform = data_proj, zorder = 3)            \n",
    "\n",
    "    #plot flight track\n",
    "    ax.plot(flight_lon, flight_lat, color = 'darkmagenta', linewidth = 2.5, zorder = 4)\n",
    "\n",
    "    #plot near-storm dropsonde locations for the given flight\n",
    "        #NOTE: Dropsondes with no wind data don't have GPS data either (5 of them total)\n",
    "    for sonde in drop_coords_and_time:\n",
    "        #ax.scatter(sonde[0], sonde[1], marker = f'${sonde[2]}$', color = 'b', s = 300)\n",
    "        df_drop_cases1316_use = df_drop_cases1316[(df_drop_cases1316['Date'] == int(sonde[3])) & (df_drop_cases1316['Time'] == int(sonde[4]))].copy()\n",
    "        \n",
    "        #skip plotting dropsondes from the given flight that aren't associated with Case 13 nor Case 16\n",
    "        if len(df_drop_cases1316_use) == 0:\n",
    "            continue\n",
    "\n",
    "        if df_drop_cases1316_use['Beyond TPW Gradient'].iloc[0] == 'Yes':\n",
    "            ax.scatter(sonde[0], sonde[1], marker = '^', color = 'k', zorder = 5, s = 250)\n",
    "        else:\n",
    "            ax.scatter(sonde[0], sonde[1], marker = '*', color = 'k', zorder = 5, s = 400)\n",
    "        \n",
    "\n",
    "    #same as above, but labeling the dropsondes by the order that they appear in the\n",
    "        #Dropsonde_Metric_Calculations.csv, NOT IN CHRONOLOGICAL ORDER!!!\n",
    "    #for z, sonde in enumerate(drop_coords_and_time):\n",
    "        #ax.scatter(sonde[0], sonde[1], marker = f'${z + 1}$', color = 'b', s = 120, zorder = 5)\n",
    "\n",
    "    #plotting the colorbars\n",
    "    #cbar0 = group_fig.colorbar(pm0, ax = ax, orientation = 'vertical', shrink = 0.75, pad = 0.25)\n",
    "    #cbar0.set_label('TPW [mm]')\n",
    "    #cbar0.ax.yaxis.set_ticks_position('left')\n",
    "    #cbar0.ax.yaxis.set_label_position('left')\n",
    "\n",
    "    #this works with GeoAxes (i.e., Cartopy's map projections)\n",
    "    if key == len(case_dict_agu) - 1:\n",
    "\n",
    "        #MIMIC TPW colorbar\n",
    "        ticks_tpw = np.arange(0, 70.5, 10)\n",
    "        #cax = group_fig.add_axes([ax.get_position().x1+0.05, ax.get_position().y0, 0.02, ax.get_position().height])\n",
    "        cax0 = group_fig.add_axes([ax.get_position().x1 + 0.04, ax.get_position().y0, 0.01, 0.755])\n",
    "        cbar0 = group_fig.colorbar(pm0, cax = cax0, ticks = ticks_tpw)\n",
    "        cbar0.set_label('TPW [mm]')\n",
    "        cbar0.ax.set_yticklabels(list(map(str, list(ticks_tpw))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "        cbar0.ax.yaxis.set_ticks_position('left')\n",
    "        cbar0.ax.yaxis.set_label_position('left')\n",
    "\n",
    "        #IMERG colorbar\n",
    "        ticks_imerg = np.array([0.1, 1, 5, 10, 20, 40])\n",
    "        cax1 = group_fig.add_axes([ax.get_position().x1 + 0.04, ax.get_position().y0, 0.01, 0.755])\n",
    "        cbar1 = group_fig.colorbar(pm1, cax = cax1, ticks = ticks_imerg)\n",
    "        cbar1.set_label('IMERG [mm hr$\\\\bf{^{-1}}$]')\n",
    "        cbar1.ax.set_yticklabels(list(map(str, list(ticks_imerg))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "        cbar1.ax.yaxis.set_ticks_position('right')\n",
    "        cbar1.ax.yaxis.set_label_position('right')\n",
    "                \n",
    "    ds_tpw.close()\n",
    "    ds_imerg.close()\n",
    "    ds.close()\n",
    "    \n",
    "    print (file_date + ' convergence plots complete!\\n')\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "#save the figure\n",
    "plt.savefig('/Users/brodenkirch/Desktop/Figure11_updated.png', bbox_inches = 'tight')\n",
    "#plt.show()  #plt.show() must come after plt.savefig() in order for the image to save properly\n",
    "#plt.clf()   #supposedly speeds things up? According to: https://www.youtube.com/watch?v=jGVIZbi9uMY\n",
    "plt.close()\n",
    "\n",
    "##decrease file size of the image by 66% without noticeable image effects (if using Matplotlib)\n",
    "##(good to use if you're producing a lot of images, see https://www.youtube.com/watch?v=fzhAseXp5B4)\n",
    "im = Image.open('/Users/brodenkirch/Desktop/Figure11_updated.png')\n",
    "\n",
    "try:\n",
    "    im2 = im.convert('P', palette = Image.Palette.ADAPTIVE)\n",
    "except:\n",
    "    #use this for older version of PIL/Pillow if the above line doesn't work, \n",
    "    #though this line will have isolated, extremely minor image effects due to \n",
    "    #only using 256 colors instead of the 3-element RGB scale\n",
    "    im2 = im.convert('P')\n",
    "\n",
    "im2.save('/Users/brodenkirch/Desktop/Figure11_updated.png')\n",
    "im.close()\n",
    "im2.close()\n",
    "\n",
    "print ('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b4148",
   "metadata": {},
   "source": [
    "#### Figure 15 for AGU Paper (2023) (merge the two plots together in PowerPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGURE 15a,c FOR AGU PAPER (2023)\n",
    "\n",
    "case_dict_agu = {0: ['20170611', 'Case 13', 17, [-95, -80, 20, 28]], \n",
    "                 1: ['20210824', 'Case 16', 16, [-75, -60, 10, 18]]}  #flight track lat/lon extent [West,East,South,North]\n",
    "conv_pres = 975  #hPa; pressure level to plot ERA5 convergence for\n",
    "\n",
    "drop_metric_cases1316_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations_OnlyCases13and16.csv')\n",
    "df_drop_cases1316 = pd.read_csv(drop_metric_cases1316_filepath)\n",
    "\n",
    "#set some baseline plot displays\n",
    "\n",
    "#matplotlib.rcParams['axes.facecolor'] = [0.9,0.9,0.9]\n",
    "matplotlib.rcParams['axes.labelsize'] = 16\n",
    "matplotlib.rcParams['axes.titlesize'] = 19\n",
    "matplotlib.rcParams['axes.labelweight'] = 'bold'\n",
    "matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "matplotlib.rcParams['xtick.labelsize'] = 16\n",
    "matplotlib.rcParams['ytick.labelsize'] = 16\n",
    "matplotlib.rcParams['legend.fontsize'] = 16\n",
    "#matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "#matplotlib.rcParams['axes.facecolor'] = 'w'\n",
    "matplotlib.rcParams['font.family'] = 'arial'\n",
    "matplotlib.rcParams['hatch.linewidth'] = 0.3\n",
    "\n",
    "data_proj = ccrs.PlateCarree()\n",
    "group_fig = plt.figure(figsize = (30,15))\n",
    "\n",
    "for key, case_info in case_dict_agu.items():\n",
    "    \n",
    "    file_date = case_info[0]\n",
    "    case_num = case_info[1]   \n",
    "    hr = case_info[2]\n",
    "    campaign_extent = case_info[3]\n",
    "\n",
    "    print (file_date + ' convergence plots in progress...')\n",
    "    \n",
    "    ###get locations of the dropsonde/Navigation/ERA5 folder and read the appropriate files in\n",
    "    day_folder = os.path.join(os.getcwd(), file_date)\n",
    "\n",
    "    #dropsonde data\n",
    "    drop_csv_path = os.path.join(day_folder, 'final_dropsonde_' + file_date + '.csv')\n",
    "    drop_csv = pd.read_csv(drop_csv_path)\n",
    "\n",
    "    if file_date[:4] == '2017':\n",
    "        campaign = 'CPEX'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "    elif file_date[:4] == '2021':\n",
    "        campaign = 'CPEXAW'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "    elif file_date[:4] == '2022':\n",
    "        campaign = 'CPEXCV'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations_CPEXCV.csv')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #ERA5 data\n",
    "    era5_folder = os.path.join(os.getcwd(), 'ERA5_Reanalysis_Data')\n",
    "    era5_path = os.path.join(era5_folder, campaign + '_ERA5_Reanalysis_Hourly_Pressure.nc')\n",
    "    ds = xr.open_dataset(era5_path)\n",
    "\n",
    "    #Navigation data\n",
    "    nav_folder = os.path.join(day_folder, 'Nav_files')\n",
    "\n",
    "    for x in os.listdir(nav_folder):\n",
    "        if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "            os.remove(os.path.join(nav_folder, x))\n",
    "\n",
    "    nav_ict_path = os.path.join(nav_folder, os.listdir(nav_folder)[0])  #only one nav file per flight\n",
    "\n",
    "    if campaign != 'CPEX':  #campaign either CPEXAW or CPEXCV\n",
    "\n",
    "        nav_ict = icartt.Dataset(nav_ict_path)    #open the ict file with icartt\n",
    "        flight_lat = nav_ict.data[\"Latitude\"]     #nav latitude, just a normal 1-D array\n",
    "        flight_lon = nav_ict.data[\"Longitude\"]    #nav longitude, just a normal 1-D array\n",
    "\n",
    "    else:  #for CPEX navigation files, open the CSV file with pandas\n",
    "           #(Navigation files for CPEX (2017) are originally .kmz not .ict,\n",
    "           #so I converted them to CSV for free using https://www.gpsvisualizer.com/convert_input\n",
    "\n",
    "        nav_ict = pd.read_csv(nav_ict_path)       #open the ict file with pandas instead\n",
    "        flight_lat = nav_ict[\"latitude\"].values   #nav latitude, just a normal 1-D array\n",
    "        flight_lon = nav_ict[\"longitude\"].values  #nav longitude, just a normal 1-D array    \n",
    "\n",
    "\n",
    "    ###calculate each near-storm dropsonde's mean lat/lon and add the sonde's time and mean lat/lon to a list to be plotted\n",
    "\n",
    "    drop_coords_and_time = []   #format: longitude, latitude, time (HHSS)\n",
    "\n",
    "    df_drop = pd.read_csv(drop_metric_filepath)\n",
    "    df_drop_use = df_drop[df_drop['Date'] == int(file_date)].copy()\n",
    "\n",
    "    for x in range(len(df_drop_use)):\n",
    "        date = str(df_drop_use['Date'].iloc[x])\n",
    "        time = str(df_drop_use['Time'].iloc[x]).zfill(6)\n",
    "        sonde_datetime = date[:4] + '-' + date[4:6] + '-' + date[6:] + ' ' + time[:2] + ':' + time[2:4] + ':' + time[4:]\n",
    "\n",
    "        drop_csv_use = drop_csv[drop_csv['Time [UTC]'] == sonde_datetime].copy()\n",
    "        drop_mean_lon = drop_csv_use['Longitude [deg]'].mean()\n",
    "        drop_mean_lat = drop_csv_use['Latitude [deg]'].mean()\n",
    "\n",
    "        sonde_info = [drop_mean_lon, drop_mean_lat, time[:4], date, time]\n",
    "        drop_coords_and_time.append(sonde_info)\n",
    "        \n",
    "    hr2 = str(hr).zfill(2)\n",
    "\n",
    "    #MIMIC TPW data\n",
    "        ##https://bin.ssec.wisc.edu/pub/mtpw2/data/\n",
    "    tpw_folder = os.path.join(day_folder, 'MIMIC_TPW_files')\n",
    "    tpw_path = os.path.join(tpw_folder, 'comp' + file_date + '.' + hr2 + '0000.nc')\n",
    "    ds_tpw = xr.open_dataset(tpw_path)\n",
    "\n",
    "    #GPM IMERG data (see IMERG.ipynb for more how to more generally download and plot IMERG data)\n",
    "        ##https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Read%20IMERG%20Data%20Using%20Python\n",
    "        ##https://disc.gsfc.nasa.gov/datasets?keywords=imerg&page=1\n",
    "        #0.1 x 0.1 gridded data, half-hourly means, using the half hour BEFORE the desired hour\n",
    "    imerg_folder = os.path.join(day_folder, 'IMERG_files')\n",
    "\n",
    "    for x in os.listdir(imerg_folder):\n",
    "        if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "            os.remove(os.path.join(imerg_folder, x))\n",
    "\n",
    "        #minutes and seconds automatically revert to zero (hour = 0, seconds = 0) for '%Y%m%d%H'\n",
    "        elif (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(seconds = 1), '%H%M%S') in x) and (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(minutes = 30), '%H%M%S') in x):\n",
    "            imerg_file = x\n",
    "            break\n",
    "        else:\n",
    "            imerg_file = 'Could not find the desired IMERG file'\n",
    "\n",
    "    #confirm that the IMERG file is from the correct day (if hr2 == '00', then this will be the previous day)\n",
    "    assert (file_date in imerg_file) or (hr2 == '00'), 'IMERG file not from the correct day'\n",
    "\n",
    "    imerg_path = os.path.join(imerg_folder, imerg_file)\n",
    "    ds_imerg = h5py.File(imerg_path, 'r')\n",
    "\n",
    "    imerg_lons = ds_imerg['Grid/lon'][:]   #Longitude Shape: (3600,)\n",
    "    imerg_lats = ds_imerg['Grid/lat'][:]   #Latitude Shape: (1800,)\n",
    "    imerg_lons, imerg_lats = np.meshgrid(imerg_lons, imerg_lats)  #Long and lat grid shape: (1800, 3600) \n",
    "\n",
    "    imerg_precip = ds_imerg['Grid/precipitation'][0][:][:]  #Original Precip Shape: (1, 3600, 1800) = (time, lon, lat)\n",
    "    imerg_precip = np.transpose(imerg_precip)               #New Precip Shape after transpose: (1800, 3600)\n",
    "\n",
    "    #mask blank data\n",
    "    imerg_precip_masked = np.ma.masked_where(imerg_precip < 0, imerg_precip)  #masks blank and bad data first (if blank data is -999 instead of NaN)\n",
    "    imerg_precip_masked = np.ma.masked_where(np.isnan(imerg_precip_masked), imerg_precip_masked)  #masks NaN values (not masked in previous line)\n",
    "\n",
    "    #creat the plot\n",
    "    ax = group_fig.add_subplot(2, 1, key+1, projection = data_proj)\n",
    "\n",
    "    conv = ds.d.sel(time = file_date).sel(level = conv_pres) * -1   #convergence of the wind (1/s)\n",
    "    conv = conv.sel(time = conv.time.dt.hour.isin(hr)) * 10**5      #convergence of the wind (times 10**5 1/s)\n",
    "\n",
    "    ##Smoothing (source: Hannah Zanowski) --> not recommended, see top of document\n",
    "        ##Metpy smooth_n_point (data to be smoothed, number of points to use in smoothing (5 to 9 are valid), and number of times the smoother is applied)\n",
    "            ##see https://unidata.github.io/MetPy/latest/api/generated/metpy.calc.smooth_n_point.html for more info\n",
    "    #conv_smoothed = mpcalc.smooth_n_point(conv,9,1)\n",
    "\n",
    "    ax.set_title('%s MIMIC TPW, GPM IMERG, and ERA5 %i hPa Convergence (%s UTC)' % (case_num, conv_pres, hr2))\n",
    "    ax.set_extent(campaign_extent, ccrs.PlateCarree()) #lat/lon bounds are [West,East,South,North]\n",
    "\n",
    "    # Add land, coastlines, and borders\n",
    "    #ax.add_feature(cfeature.LAND, facecolor='0.8')\n",
    "    ax.coastlines(ls = '-', linewidth = 0.5, color = 'gray')\n",
    "\n",
    "    #plot MIMIC TPW\n",
    "    tpw_levels = np.arange(0, 70.5, 2)\n",
    "    pm0 = ax.contourf(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, levels = tpw_levels,\n",
    "                      extend = 'max', cmap = cm.jet, transform = data_proj)\n",
    "#             pm0 = ax.pcolormesh(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, vmin = 0, vmax = 70,\n",
    "#                                 cmap = cm.jet, transform = data_proj, zorder = 0)\n",
    "\n",
    "    #plot IMERG Rain Rate\n",
    "    pm1 = ax.contourf(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "                      levels = np.logspace(np.log10(0.1), np.log10(40), num = len(tpw_levels)), \n",
    "                      norm = 'log', extend = 'max', \n",
    "                      cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "#             pm1 = ax.pcolormesh(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "#                                 norm = mplc.LogNorm(vmin = 0.1, vmax = 40), \n",
    "#                                 cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "\n",
    "    #gridlines\n",
    "    gl = ax.gridlines(crs = ccrs.PlateCarree(), draw_labels = True, linewidth = 0.5, \n",
    "                      color = 'gray', alpha = 0.5, linestyle = '--', zorder = 2)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {'size':16, 'color':'black'}\n",
    "    gl.ylabel_style = {'size':16, 'color':'black'}\n",
    "    \n",
    "    level_array = np.arange(1, 201.1, 2)\n",
    "    linewidth_array = np.full_like(level_array, 0.6)\n",
    "    linewidth_array[3:] = 2.5   #values 7 x 10^-5 s^-1 and greater will have thicker contours\n",
    "\n",
    "    #plot ERA5 convergence\n",
    "    ax.contour(ds.longitude, ds.latitude, conv[0].values, levels = level_array,\n",
    "               colors = 'k', linewidths = linewidth_array, transform = data_proj, zorder = 3)            \n",
    "\n",
    "    #plot flight track\n",
    "    ax.plot(flight_lon, flight_lat, color = 'darkmagenta', linewidth = 2.5, zorder = 4)\n",
    "\n",
    "    #plot near-storm dropsonde locations for the given flight\n",
    "        #NOTE: Dropsondes with no wind data don't have GPS data either (5 of them total)\n",
    "    for sonde in drop_coords_and_time:\n",
    "        #ax.scatter(sonde[0], sonde[1], marker = f'${sonde[2]}$', color = 'b', s = 300)\n",
    "        df_drop_cases1316_use = df_drop_cases1316[(df_drop_cases1316['Date'] == int(sonde[3])) & (df_drop_cases1316['Time'] == int(sonde[4]))].copy()\n",
    "        \n",
    "        #skip plotting dropsondes from the given flight that aren't associated with Case 13 nor Case 16\n",
    "        if len(df_drop_cases1316_use) == 0:\n",
    "            continue\n",
    "\n",
    "        if df_drop_cases1316_use['Beyond TPW Gradient'].iloc[0] == 'Yes':\n",
    "            ax.scatter(sonde[0], sonde[1], marker = '^', color = 'k', zorder = 5, s = 250)\n",
    "        else:\n",
    "            ax.scatter(sonde[0], sonde[1], marker = '*', color = 'k', zorder = 5, s = 400)\n",
    "\n",
    "    #same as above, but labeling the dropsondes by the order that they appear in the\n",
    "        #Dropsonde_Metric_Calculations.csv, NOT IN CHRONOLOGICAL ORDER!!!\n",
    "    #for z, sonde in enumerate(drop_coords_and_time):\n",
    "        #ax.scatter(sonde[0], sonde[1], marker = f'${z + 1}$', color = 'b', s = 120, zorder = 5)\n",
    "\n",
    "    #plotting the colorbars\n",
    "    #cbar0 = group_fig.colorbar(pm0, ax = ax, orientation = 'vertical', shrink = 0.75, pad = 0.25)\n",
    "    #cbar0.set_label('TPW [mm]')\n",
    "    #cbar0.ax.yaxis.set_ticks_position('left')\n",
    "    #cbar0.ax.yaxis.set_label_position('left')\n",
    "\n",
    "    #this works with GeoAxes (i.e., Cartopy's map projections)\n",
    "    if key == len(case_dict_agu) - 1:\n",
    "\n",
    "        #MIMIC TPW colorbar\n",
    "        ticks_tpw = np.arange(0, 70.5, 10)\n",
    "        #cax = group_fig.add_axes([ax.get_position().x1+0.05, ax.get_position().y0, 0.02, ax.get_position().height])\n",
    "        cax0 = group_fig.add_axes([ax.get_position().x1 + 0.04, ax.get_position().y0, 0.01, 0.755])\n",
    "        cbar0 = group_fig.colorbar(pm0, cax = cax0, ticks = ticks_tpw)\n",
    "        cbar0.set_label('TPW [mm]')\n",
    "        cbar0.ax.set_yticklabels(list(map(str, list(ticks_tpw))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "        cbar0.ax.yaxis.set_ticks_position('left')\n",
    "        cbar0.ax.yaxis.set_label_position('left')\n",
    "\n",
    "        #IMERG colorbar\n",
    "        ticks_imerg = np.array([0.1, 1, 5, 10, 20, 40])\n",
    "        cax1 = group_fig.add_axes([ax.get_position().x1 + 0.04, ax.get_position().y0, 0.01, 0.755])\n",
    "        cbar1 = group_fig.colorbar(pm1, cax = cax1, ticks = ticks_imerg)\n",
    "        cbar1.set_label('IMERG [mm hr$\\\\bf{^{-1}}$]')\n",
    "        cbar1.ax.set_yticklabels(list(map(str, list(ticks_imerg))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "        cbar1.ax.yaxis.set_ticks_position('right')\n",
    "        cbar1.ax.yaxis.set_label_position('right')\n",
    "                \n",
    "    ds_tpw.close()\n",
    "    ds_imerg.close()\n",
    "    ds.close()\n",
    "    \n",
    "    print (file_date + ' convergence plots complete!\\n')\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "#save the figure\n",
    "plt.savefig('/Users/brodenkirch/Desktop/Figure15ac_updated.png', bbox_inches = 'tight')\n",
    "#plt.show()  #plt.show() must come after plt.savefig() in order for the image to save properly\n",
    "#plt.clf()   #supposedly speeds things up? According to: https://www.youtube.com/watch?v=jGVIZbi9uMY\n",
    "plt.close()\n",
    "\n",
    "##decrease file size of the image by 66% without noticeable image effects (if using Matplotlib)\n",
    "##(good to use if you're producing a lot of images, see https://www.youtube.com/watch?v=fzhAseXp5B4)\n",
    "im = Image.open('/Users/brodenkirch/Desktop/Figure15ac_updated.png')\n",
    "\n",
    "try:\n",
    "    im2 = im.convert('P', palette = Image.Palette.ADAPTIVE)\n",
    "except:\n",
    "    #use this for older version of PIL/Pillow if the above line doesn't work, \n",
    "    #though this line will have isolated, extremely minor image effects due to \n",
    "    #only using 256 colors instead of the 3-element RGB scale\n",
    "    im2 = im.convert('P')\n",
    "\n",
    "im2.save('/Users/brodenkirch/Desktop/Figure15ac_updated.png')\n",
    "im.close()\n",
    "im2.close()\n",
    "\n",
    "print ('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013fbf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGURE 15b,d FOR AGU PAPER (2023)\n",
    "\n",
    "case_dict_agu = {0: ['20170611', 'Case 13', 19, [-95, -80, 20, 28]], \n",
    "                 1: ['20210824', 'Case 16', 18, [-75, -60, 10, 18]]}  #flight track lat/lon extent [West,East,South,North]\n",
    "conv_pres = 975  #hPa; pressure level to plot ERA5 convergence for\n",
    "\n",
    "drop_metric_cases1316_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations_OnlyCases13and16.csv')\n",
    "df_drop_cases1316 = pd.read_csv(drop_metric_cases1316_filepath)\n",
    "\n",
    "#set some baseline plot displays\n",
    "\n",
    "#matplotlib.rcParams['axes.facecolor'] = [0.9,0.9,0.9]\n",
    "matplotlib.rcParams['axes.labelsize'] = 16\n",
    "matplotlib.rcParams['axes.titlesize'] = 19\n",
    "matplotlib.rcParams['axes.labelweight'] = 'bold'\n",
    "matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "matplotlib.rcParams['xtick.labelsize'] = 16\n",
    "matplotlib.rcParams['ytick.labelsize'] = 16\n",
    "matplotlib.rcParams['legend.fontsize'] = 16\n",
    "#matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "#matplotlib.rcParams['axes.facecolor'] = 'w'\n",
    "matplotlib.rcParams['font.family'] = 'arial'\n",
    "matplotlib.rcParams['hatch.linewidth'] = 0.3\n",
    "\n",
    "data_proj = ccrs.PlateCarree()\n",
    "group_fig = plt.figure(figsize = (30,15))\n",
    "\n",
    "for key, case_info in case_dict_agu.items():\n",
    "    \n",
    "    file_date = case_info[0]\n",
    "    case_num = case_info[1]   \n",
    "    hr = case_info[2]\n",
    "    campaign_extent = case_info[3]\n",
    "\n",
    "    print (file_date + ' convergence plots in progress...')\n",
    "    \n",
    "    ###get locations of the dropsonde/Navigation/ERA5 folder and read the appropriate files in\n",
    "    day_folder = os.path.join(os.getcwd(), file_date)\n",
    "\n",
    "    #dropsonde data\n",
    "    drop_csv_path = os.path.join(day_folder, 'final_dropsonde_' + file_date + '.csv')\n",
    "    drop_csv = pd.read_csv(drop_csv_path)\n",
    "\n",
    "    if file_date[:4] == '2017':\n",
    "        campaign = 'CPEX'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "    elif file_date[:4] == '2021':\n",
    "        campaign = 'CPEXAW'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "    elif file_date[:4] == '2022':\n",
    "        campaign = 'CPEXCV'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations_CPEXCV.csv')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #ERA5 data\n",
    "    era5_folder = os.path.join(os.getcwd(), 'ERA5_Reanalysis_Data')\n",
    "    era5_path = os.path.join(era5_folder, campaign + '_ERA5_Reanalysis_Hourly_Pressure.nc')\n",
    "    ds = xr.open_dataset(era5_path)\n",
    "\n",
    "    #Navigation data\n",
    "    nav_folder = os.path.join(day_folder, 'Nav_files')\n",
    "\n",
    "    for x in os.listdir(nav_folder):\n",
    "        if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "            os.remove(os.path.join(nav_folder, x))\n",
    "\n",
    "    nav_ict_path = os.path.join(nav_folder, os.listdir(nav_folder)[0])  #only one nav file per flight\n",
    "\n",
    "    if campaign != 'CPEX':  #campaign either CPEXAW or CPEXCV\n",
    "\n",
    "        nav_ict = icartt.Dataset(nav_ict_path)    #open the ict file with icartt\n",
    "        flight_lat = nav_ict.data[\"Latitude\"]     #nav latitude, just a normal 1-D array\n",
    "        flight_lon = nav_ict.data[\"Longitude\"]    #nav longitude, just a normal 1-D array\n",
    "\n",
    "    else:  #for CPEX navigation files, open the CSV file with pandas\n",
    "           #(Navigation files for CPEX (2017) are originally .kmz not .ict,\n",
    "           #so I converted them to CSV for free using https://www.gpsvisualizer.com/convert_input\n",
    "\n",
    "        nav_ict = pd.read_csv(nav_ict_path)       #open the ict file with pandas instead\n",
    "        flight_lat = nav_ict[\"latitude\"].values   #nav latitude, just a normal 1-D array\n",
    "        flight_lon = nav_ict[\"longitude\"].values  #nav longitude, just a normal 1-D array    \n",
    "\n",
    "\n",
    "    ###calculate each near-storm dropsonde's mean lat/lon and add the sonde's time and mean lat/lon to a list to be plotted\n",
    "\n",
    "    drop_coords_and_time = []   #format: longitude, latitude, time (HHSS)\n",
    "\n",
    "    df_drop = pd.read_csv(drop_metric_filepath)\n",
    "    df_drop_use = df_drop[df_drop['Date'] == int(file_date)].copy()\n",
    "\n",
    "    for x in range(len(df_drop_use)):\n",
    "        date = str(df_drop_use['Date'].iloc[x])\n",
    "        time = str(df_drop_use['Time'].iloc[x]).zfill(6)\n",
    "        sonde_datetime = date[:4] + '-' + date[4:6] + '-' + date[6:] + ' ' + time[:2] + ':' + time[2:4] + ':' + time[4:]\n",
    "\n",
    "        drop_csv_use = drop_csv[drop_csv['Time [UTC]'] == sonde_datetime].copy()\n",
    "        drop_mean_lon = drop_csv_use['Longitude [deg]'].mean()\n",
    "        drop_mean_lat = drop_csv_use['Latitude [deg]'].mean()\n",
    "\n",
    "        sonde_info = [drop_mean_lon, drop_mean_lat, time[:4], date, time]\n",
    "        drop_coords_and_time.append(sonde_info)\n",
    "        \n",
    "    hr2 = str(hr).zfill(2)\n",
    "\n",
    "    #MIMIC TPW data\n",
    "        ##https://bin.ssec.wisc.edu/pub/mtpw2/data/\n",
    "    tpw_folder = os.path.join(day_folder, 'MIMIC_TPW_files')\n",
    "    tpw_path = os.path.join(tpw_folder, 'comp' + file_date + '.' + hr2 + '0000.nc')\n",
    "    ds_tpw = xr.open_dataset(tpw_path)\n",
    "\n",
    "    #GPM IMERG data (see IMERG.ipynb for more how to more generally download and plot IMERG data)\n",
    "        ##https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Read%20IMERG%20Data%20Using%20Python\n",
    "        ##https://disc.gsfc.nasa.gov/datasets?keywords=imerg&page=1\n",
    "        #0.1 x 0.1 gridded data, half-hourly means, using the half hour BEFORE the desired hour\n",
    "    imerg_folder = os.path.join(day_folder, 'IMERG_files')\n",
    "\n",
    "    for x in os.listdir(imerg_folder):\n",
    "        if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "            os.remove(os.path.join(imerg_folder, x))\n",
    "\n",
    "        #minutes and seconds automatically revert to zero (hour = 0, seconds = 0) for '%Y%m%d%H'\n",
    "        elif (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(seconds = 1), '%H%M%S') in x) and (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(minutes = 30), '%H%M%S') in x):\n",
    "            imerg_file = x\n",
    "            break\n",
    "        else:\n",
    "            imerg_file = 'Could not find the desired IMERG file'\n",
    "\n",
    "    #confirm that the IMERG file is from the correct day (if hr2 == '00', then this will be the previous day)\n",
    "    assert (file_date in imerg_file) or (hr2 == '00'), 'IMERG file not from the correct day'\n",
    "\n",
    "    imerg_path = os.path.join(imerg_folder, imerg_file)\n",
    "    ds_imerg = h5py.File(imerg_path, 'r')\n",
    "\n",
    "    imerg_lons = ds_imerg['Grid/lon'][:]   #Longitude Shape: (3600,)\n",
    "    imerg_lats = ds_imerg['Grid/lat'][:]   #Latitude Shape: (1800,)\n",
    "    imerg_lons, imerg_lats = np.meshgrid(imerg_lons, imerg_lats)  #Long and lat grid shape: (1800, 3600) \n",
    "\n",
    "    imerg_precip = ds_imerg['Grid/precipitation'][0][:][:]  #Original Precip Shape: (1, 3600, 1800) = (time, lon, lat)\n",
    "    imerg_precip = np.transpose(imerg_precip)               #New Precip Shape after transpose: (1800, 3600)\n",
    "\n",
    "    #mask blank data\n",
    "    imerg_precip_masked = np.ma.masked_where(imerg_precip < 0, imerg_precip)  #masks blank and bad data first (if blank data is -999 instead of NaN)\n",
    "    imerg_precip_masked = np.ma.masked_where(np.isnan(imerg_precip_masked), imerg_precip_masked)  #masks NaN values (not masked in previous line)\n",
    "\n",
    "    #creat the plot\n",
    "    ax = group_fig.add_subplot(2, 1, key+1, projection = data_proj)\n",
    "\n",
    "    conv = ds.d.sel(time = file_date).sel(level = conv_pres) * -1   #convergence of the wind (1/s)\n",
    "    conv = conv.sel(time = conv.time.dt.hour.isin(hr)) * 10**5      #convergence of the wind (times 10**5 1/s)\n",
    "\n",
    "    ##Smoothing (source: Hannah Zanowski) --> not recommended, see top of document\n",
    "        ##Metpy smooth_n_point (data to be smoothed, number of points to use in smoothing (5 to 9 are valid), and number of times the smoother is applied)\n",
    "            ##see https://unidata.github.io/MetPy/latest/api/generated/metpy.calc.smooth_n_point.html for more info\n",
    "    #conv_smoothed = mpcalc.smooth_n_point(conv,9,1)\n",
    "\n",
    "    ax.set_title('%s MIMIC TPW, GPM IMERG, and ERA5 %i hPa Convergence (%s UTC)' % (case_num, conv_pres, hr2))\n",
    "    ax.set_extent(campaign_extent, ccrs.PlateCarree()) #lat/lon bounds are [West,East,South,North]\n",
    "\n",
    "    # Add land, coastlines, and borders\n",
    "    #ax.add_feature(cfeature.LAND, facecolor='0.8')\n",
    "    ax.coastlines(ls = '-', linewidth = 0.5, color = 'gray')\n",
    "\n",
    "    #plot MIMIC TPW\n",
    "    tpw_levels = np.arange(0, 70.5, 2)\n",
    "    pm0 = ax.contourf(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, levels = tpw_levels,\n",
    "                      extend = 'max', cmap = cm.jet, transform = data_proj)\n",
    "#             pm0 = ax.pcolormesh(ds_tpw.lonArr, ds_tpw.latArr, ds_tpw.tpwGrid, vmin = 0, vmax = 70,\n",
    "#                                 cmap = cm.jet, transform = data_proj, zorder = 0)\n",
    "\n",
    "    #plot IMERG Rain Rate\n",
    "    pm1 = ax.contourf(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "                      levels = np.logspace(np.log10(0.1), np.log10(40), num = len(tpw_levels)), \n",
    "                      norm = 'log', extend = 'max', \n",
    "                      cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "#             pm1 = ax.pcolormesh(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "#                                 norm = mplc.LogNorm(vmin = 0.1, vmax = 40), \n",
    "#                                 cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "\n",
    "    #gridlines\n",
    "    gl = ax.gridlines(crs = ccrs.PlateCarree(), draw_labels = True, linewidth = 0.5, \n",
    "                      color = 'gray', alpha = 0.5, linestyle = '--', zorder = 2)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {'size':16, 'color':'black'}\n",
    "    gl.ylabel_style = {'size':16, 'color':'black'}\n",
    "    \n",
    "    level_array = np.arange(1, 201.1, 2)\n",
    "    linewidth_array = np.full_like(level_array, 0.6)\n",
    "    linewidth_array[3:] = 2.5   #values 7 x 10^-5 s^-1 and greater will have thicker contours\n",
    "\n",
    "    #plot ERA5 convergence\n",
    "    ax.contour(ds.longitude, ds.latitude, conv[0].values, levels = level_array,\n",
    "               colors = 'k', linewidths = linewidth_array, transform = data_proj, zorder = 3)            \n",
    "\n",
    "    #plot flight track\n",
    "    ax.plot(flight_lon, flight_lat, color = 'darkmagenta', linewidth = 2.5, zorder = 4)\n",
    "\n",
    "    #plot near-storm dropsonde locations for the given flight\n",
    "        #NOTE: Dropsondes with no wind data don't have GPS data either (5 of them total)\n",
    "    for sonde in drop_coords_and_time:\n",
    "        #ax.scatter(sonde[0], sonde[1], marker = f'${sonde[2]}$', color = 'b', s = 300)\n",
    "        df_drop_cases1316_use = df_drop_cases1316[(df_drop_cases1316['Date'] == int(sonde[3])) & (df_drop_cases1316['Time'] == int(sonde[4]))].copy()\n",
    "        \n",
    "        #skip plotting dropsondes from the given flight that aren't associated with Case 13 nor Case 16\n",
    "        if len(df_drop_cases1316_use) == 0:\n",
    "            continue\n",
    "\n",
    "        if df_drop_cases1316_use['Beyond TPW Gradient'].iloc[0] == 'Yes':\n",
    "            ax.scatter(sonde[0], sonde[1], marker = '^', color = 'k', zorder = 5, s = 250)\n",
    "        else:\n",
    "            ax.scatter(sonde[0], sonde[1], marker = '*', color = 'k', zorder = 5, s = 400)\n",
    "\n",
    "    #same as above, but labeling the dropsondes by the order that they appear in the\n",
    "        #Dropsonde_Metric_Calculations.csv, NOT IN CHRONOLOGICAL ORDER!!!\n",
    "    #for z, sonde in enumerate(drop_coords_and_time):\n",
    "        #ax.scatter(sonde[0], sonde[1], marker = f'${z + 1}$', color = 'b', s = 120, zorder = 5)\n",
    "\n",
    "    #plotting the colorbars\n",
    "    #cbar0 = group_fig.colorbar(pm0, ax = ax, orientation = 'vertical', shrink = 0.75, pad = 0.25)\n",
    "    #cbar0.set_label('TPW [mm]')\n",
    "    #cbar0.ax.yaxis.set_ticks_position('left')\n",
    "    #cbar0.ax.yaxis.set_label_position('left')\n",
    "\n",
    "    #this works with GeoAxes (i.e., Cartopy's map projections)\n",
    "    if key == len(case_dict_agu) - 1:\n",
    "\n",
    "        #MIMIC TPW colorbar\n",
    "        ticks_tpw = np.arange(0, 70.5, 10)\n",
    "        #cax = group_fig.add_axes([ax.get_position().x1+0.05, ax.get_position().y0, 0.02, ax.get_position().height])\n",
    "        cax0 = group_fig.add_axes([ax.get_position().x1 + 0.04, ax.get_position().y0, 0.01, 0.755])\n",
    "        cbar0 = group_fig.colorbar(pm0, cax = cax0, ticks = ticks_tpw)\n",
    "        cbar0.set_label('TPW [mm]')\n",
    "        cbar0.ax.set_yticklabels(list(map(str, list(ticks_tpw))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "        cbar0.ax.yaxis.set_ticks_position('left')\n",
    "        cbar0.ax.yaxis.set_label_position('left')\n",
    "\n",
    "        #IMERG colorbar\n",
    "        ticks_imerg = np.array([0.1, 1, 5, 10, 20, 40])\n",
    "        cax1 = group_fig.add_axes([ax.get_position().x1 + 0.04, ax.get_position().y0, 0.01, 0.755])\n",
    "        cbar1 = group_fig.colorbar(pm1, cax = cax1, ticks = ticks_imerg)\n",
    "        cbar1.set_label('IMERG [mm hr$\\\\bf{^{-1}}$]')\n",
    "        cbar1.ax.set_yticklabels(list(map(str, list(ticks_imerg))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "        cbar1.ax.yaxis.set_ticks_position('right')\n",
    "        cbar1.ax.yaxis.set_label_position('right')\n",
    "                \n",
    "    ds_tpw.close()\n",
    "    ds_imerg.close()\n",
    "    ds.close()\n",
    "    \n",
    "    print (file_date + ' convergence plots complete!\\n')\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "#save the figure\n",
    "plt.savefig('/Users/brodenkirch/Desktop/Figure15bd_updated.png', bbox_inches = 'tight')\n",
    "#plt.show()  #plt.show() must come after plt.savefig() in order for the image to save properly\n",
    "#plt.clf()   #supposedly speeds things up? According to: https://www.youtube.com/watch?v=jGVIZbi9uMY\n",
    "plt.close()\n",
    "\n",
    "##decrease file size of the image by 66% without noticeable image effects (if using Matplotlib)\n",
    "##(good to use if you're producing a lot of images, see https://www.youtube.com/watch?v=fzhAseXp5B4)\n",
    "im = Image.open('/Users/brodenkirch/Desktop/Figure15bd_updated.png')\n",
    "\n",
    "try:\n",
    "    im2 = im.convert('P', palette = Image.Palette.ADAPTIVE)\n",
    "except:\n",
    "    #use this for older version of PIL/Pillow if the above line doesn't work, \n",
    "    #though this line will have isolated, extremely minor image effects due to \n",
    "    #only using 256 colors instead of the 3-element RGB scale\n",
    "    im2 = im.convert('P')\n",
    "\n",
    "im2.save('/Users/brodenkirch/Desktop/Figure15bd_updated.png')\n",
    "im.close()\n",
    "im2.close()\n",
    "\n",
    "print ('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfe48e",
   "metadata": {},
   "source": [
    "#### Figure 2 for AGU Paper (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83defd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGURE 2 FOR AGU PAPER (2023)\n",
    "\n",
    "case_dict_agu = {0: ['20170610', 'an Isolated', 20, [-85, -60, 19, 31]], \n",
    "                 1: ['20170601', 'an Organized', 19, [-98, -73, 19, 31]], \n",
    "                 2: ['20170602', 'a Scattered', 22, [-98, -73, 19, 31]]}  #flight track lat/lon extent [West,East,South,North]\n",
    "\n",
    "#set some baseline plot displays\n",
    "\n",
    "#matplotlib.rcParams['axes.facecolor'] = [0.9,0.9,0.9]\n",
    "matplotlib.rcParams['axes.labelsize'] = 16\n",
    "matplotlib.rcParams['axes.titlesize'] = 18\n",
    "matplotlib.rcParams['axes.labelweight'] = 'bold'\n",
    "matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "matplotlib.rcParams['xtick.labelsize'] = 16\n",
    "matplotlib.rcParams['ytick.labelsize'] = 16\n",
    "matplotlib.rcParams['legend.fontsize'] = 16\n",
    "#matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "#matplotlib.rcParams['axes.facecolor'] = 'w'\n",
    "matplotlib.rcParams['font.family'] = 'arial'\n",
    "matplotlib.rcParams['hatch.linewidth'] = 0.3\n",
    "\n",
    "data_proj = ccrs.PlateCarree()\n",
    "group_fig = plt.figure(figsize = (48,18))\n",
    "\n",
    "for key, case_info in case_dict_agu.items():\n",
    "    \n",
    "    file_date = case_info[0]\n",
    "    conv_type = case_info[1]   \n",
    "    hr = case_info[2]\n",
    "    campaign_extent = case_info[3]\n",
    "\n",
    "    print (file_date + ' IMERG plots in progress...')\n",
    "    \n",
    "    ###get locations of the dropsonde/Navigation/ERA5 folder and read the appropriate files in\n",
    "    day_folder = os.path.join(os.getcwd(), file_date)\n",
    "\n",
    "    #dropsonde data\n",
    "    drop_csv_path = os.path.join(day_folder, 'final_dropsonde_' + file_date + '.csv')\n",
    "    drop_csv = pd.read_csv(drop_csv_path)\n",
    "\n",
    "    if file_date[:4] == '2017':\n",
    "        campaign = 'CPEX'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "    elif file_date[:4] == '2021':\n",
    "        campaign = 'CPEXAW'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations.csv')\n",
    "    elif file_date[:4] == '2022':\n",
    "        campaign = 'CPEXCV'\n",
    "        drop_metric_filepath = os.path.join(os.getcwd(), 'Dropsonde_Metric_Calculations_CPEXCV.csv')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #Navigation data\n",
    "    nav_folder = os.path.join(day_folder, 'Nav_files')\n",
    "\n",
    "    for x in os.listdir(nav_folder):\n",
    "        if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "            os.remove(os.path.join(nav_folder, x))\n",
    "\n",
    "    nav_ict_path = os.path.join(nav_folder, os.listdir(nav_folder)[0])  #only one nav file per flight\n",
    "\n",
    "    if campaign != 'CPEX':  #campaign either CPEXAW or CPEXCV\n",
    "\n",
    "        nav_ict = icartt.Dataset(nav_ict_path)    #open the ict file with icartt\n",
    "        flight_lat = nav_ict.data[\"Latitude\"]     #nav latitude, just a normal 1-D array\n",
    "        flight_lon = nav_ict.data[\"Longitude\"]    #nav longitude, just a normal 1-D array\n",
    "\n",
    "    else:  #for CPEX navigation files, open the CSV file with pandas\n",
    "           #(Navigation files for CPEX (2017) are originally .kmz not .ict,\n",
    "           #so I converted them to CSV for free using https://www.gpsvisualizer.com/convert_input\n",
    "\n",
    "        nav_ict = pd.read_csv(nav_ict_path)       #open the ict file with pandas instead\n",
    "        flight_lat = nav_ict[\"latitude\"].values   #nav latitude, just a normal 1-D array\n",
    "        flight_lon = nav_ict[\"longitude\"].values  #nav longitude, just a normal 1-D array    \n",
    "\n",
    "\n",
    "    ###calculate each near-storm dropsonde's mean lat/lon and add the sonde's time and mean lat/lon to a list to be plotted\n",
    "\n",
    "    drop_coords_and_time = []   #format: longitude, latitude, time (HHSS)\n",
    "\n",
    "    df_drop = pd.read_csv(drop_metric_filepath)\n",
    "    df_drop_use = df_drop[df_drop['Date'] == int(file_date)].copy()\n",
    "\n",
    "    for x in range(len(df_drop_use)):\n",
    "        date = str(df_drop_use['Date'].iloc[x])\n",
    "        time = str(df_drop_use['Time'].iloc[x]).zfill(6)\n",
    "        sonde_datetime = date[:4] + '-' + date[4:6] + '-' + date[6:] + ' ' + time[:2] + ':' + time[2:4] + ':' + time[4:]\n",
    "\n",
    "        drop_csv_use = drop_csv[drop_csv['Time [UTC]'] == sonde_datetime].copy()\n",
    "        drop_mean_lon = drop_csv_use['Longitude [deg]'].mean()\n",
    "        drop_mean_lat = drop_csv_use['Latitude [deg]'].mean()\n",
    "\n",
    "        sonde_info = [drop_mean_lon, drop_mean_lat, time[:4]]\n",
    "        drop_coords_and_time.append(sonde_info)\n",
    "        \n",
    "    hr2 = str(hr).zfill(2)\n",
    "\n",
    "    #GPM IMERG data (see IMERG.ipynb for more how to more generally download and plot IMERG data)\n",
    "       ##https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Read%20IMERG%20Data%20Using%20Python\n",
    "       ##https://disc.gsfc.nasa.gov/datasets?keywords=imerg&page=1\n",
    "       #0.1 x 0.1 gridded data, half-hourly means, using the half hour BEFORE the desired hour\n",
    "    imerg_folder = os.path.join(day_folder, 'IMERG_files')\n",
    "\n",
    "    for x in os.listdir(imerg_folder):\n",
    "        if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "            os.remove(os.path.join(imerg_folder, x))\n",
    "\n",
    "        #minutes and seconds automatically revert to zero (hour = 0, seconds = 0) for '%Y%m%d%H'\n",
    "        elif (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(seconds = 1), '%H%M%S') in x) and (datetime.strftime(datetime.strptime(file_date + hr2, '%Y%m%d%H') - timedelta(minutes = 30), '%H%M%S') in x):\n",
    "            imerg_file = x\n",
    "            break\n",
    "        else:\n",
    "            imerg_file = 'Could not find the desired IMERG file'\n",
    "\n",
    "    #confirm that the IMERG file is from the correct day (if hr2 == '00', then this will be the previous day)\n",
    "    assert (file_date in imerg_file) or (hr2 == '00'), 'IMERG file not from the correct day'\n",
    "\n",
    "    imerg_path = os.path.join(imerg_folder, imerg_file)\n",
    "    ds_imerg = h5py.File(imerg_path, 'r')\n",
    "\n",
    "    imerg_lons = ds_imerg['Grid/lon'][:]   #Longitude Shape: (3600,)\n",
    "    imerg_lats = ds_imerg['Grid/lat'][:]   #Latitude Shape: (1800,)\n",
    "    imerg_lons, imerg_lats = np.meshgrid(imerg_lons, imerg_lats)  #Long and lat grid shape: (1800, 3600) \n",
    "\n",
    "    imerg_precip = ds_imerg['Grid/precipitation'][0][:][:]  #Original Precip Shape: (1, 3600, 1800) = (time, lon, lat)\n",
    "    imerg_precip = np.transpose(imerg_precip)               #New Precip Shape after transpose: (1800, 3600)\n",
    "\n",
    "    #mask blank data\n",
    "    imerg_precip_masked = np.ma.masked_where(imerg_precip < 0, imerg_precip)  #masks blank and bad data first (if blank data is -999 instead of NaN)\n",
    "    imerg_precip_masked = np.ma.masked_where(np.isnan(imerg_precip_masked), imerg_precip_masked)  #masks NaN values (not masked in previous line)\n",
    "\n",
    "    #creat the plot\n",
    "    ax = group_fig.add_subplot(3, 1, key+1, projection = data_proj)\n",
    "\n",
    "    ax.set_title('GPM IMERG for %s Convective Case' % (conv_type))\n",
    "    ax.set_extent(campaign_extent, ccrs.PlateCarree()) #lat/lon bounds are [West,East,South,North]\n",
    "\n",
    "    # Add land, coastlines, and borders\n",
    "    #ax.add_feature(cfeature.LAND, facecolor='0.8')\n",
    "    ax.coastlines(ls = '-', linewidth = 0.5, color = 'gray')\n",
    "\n",
    "    #plot IMERG Rain Rate\n",
    "    tpw_levels = np.arange(0, 70.5, 2)\n",
    "    pm1 = ax.contourf(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "                      levels = np.logspace(np.log10(0.1), np.log10(40), num = len(tpw_levels)), \n",
    "                      norm = 'log', extend = 'max', \n",
    "                      cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "#             pm1 = ax.pcolormesh(imerg_lons, imerg_lats, imerg_precip_masked, \n",
    "#                                 norm = mplc.LogNorm(vmin = 0.1, vmax = 40), \n",
    "#                                 cmap = cm.jet, transform = data_proj, zorder = 1)\n",
    "\n",
    "    #gridlines\n",
    "    gl = ax.gridlines(crs = ccrs.PlateCarree(), draw_labels = True, linewidth = 0.5, \n",
    "                      color = 'gray', alpha = 0.5, linestyle = '--', zorder = 2)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {'size':16, 'color':'black'}\n",
    "    gl.ylabel_style = {'size':16, 'color':'black'}            \n",
    "\n",
    "    #plot flight track\n",
    "    ax.plot(flight_lon, flight_lat, color = 'salmon', linewidth = 1.5, zorder = 4)\n",
    "\n",
    "    #plot near-storm dropsonde locations for the given flight\n",
    "        #NOTE: Dropsondes with no wind data don't have GPS data either (5 of them total)\n",
    "    for sonde in drop_coords_and_time:\n",
    "        #ax.scatter(sonde[0], sonde[1], marker = f'${sonde[2]}$', color = 'b', s = 300)\n",
    "        ax.scatter(sonde[0], sonde[1], marker = '*', color = 'k', zorder = 5)\n",
    "\n",
    "    #same as above, but labeling the dropsondes by the order that they appear in the\n",
    "        #Dropsonde_Metric_Calculations.csv, NOT IN CHRONOLOGICAL ORDER!!!\n",
    "    #for z, sonde in enumerate(drop_coords_and_time):\n",
    "        #ax.scatter(sonde[0], sonde[1], marker = f'${z + 1}$', color = 'b', s = 120, zorder = 5)\n",
    "\n",
    "    #plotting the colorbars\n",
    "    #cbar0 = group_fig.colorbar(pm0, ax = ax, orientation = 'vertical', shrink = 0.75, pad = 0.25)\n",
    "    #cbar0.set_label('IMERG [mm hr$\\\\bf{^{-1}}$]')\n",
    "    #cbar0.ax.yaxis.set_ticks_position('left')\n",
    "    #cbar0.ax.yaxis.set_label_position('left')\n",
    "\n",
    "    #this works with GeoAxes (i.e., Cartopy's map projections)\n",
    "    if key == len(case_dict_agu) - 1:\n",
    "\n",
    "        #IMERG colorbar\n",
    "        ticks_imerg = np.array([0.1, 1, 5, 10, 20, 40])\n",
    "        cax1 = group_fig.add_axes([ax.get_position().x1 + 0.01, ax.get_position().y0, 0.01, 0.755])\n",
    "        cbar1 = group_fig.colorbar(pm1, cax = cax1, ticks = ticks_imerg)\n",
    "        cbar1.set_label('IMERG [mm hr$\\\\bf{^{-1}}$]')\n",
    "        cbar1.ax.set_yticklabels(list(map(str, list(ticks_imerg))))  #labels automatically default to tick values given to ticks parameter in fig.colorbar(), unless you're using a log scale I guess\n",
    "        cbar1.ax.yaxis.set_ticks_position('right')\n",
    "        cbar1.ax.yaxis.set_label_position('right')\n",
    "                \n",
    "    ds_imerg.close()\n",
    "    \n",
    "    print (file_date + ' IMERG plots complete!\\n')\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "#save the figure\n",
    "plt.savefig('/Users/brodenkirch/Desktop/Figure2_updated.png', bbox_inches = 'tight')\n",
    "#plt.show()  #plt.show() must come after plt.savefig() in order for the image to save properly\n",
    "#plt.clf()   #supposedly speeds things up? According to: https://www.youtube.com/watch?v=jGVIZbi9uMY\n",
    "plt.close()\n",
    "\n",
    "##decrease file size of the image by 66% without noticeable image effects (if using Matplotlib)\n",
    "##(good to use if you're producing a lot of images, see https://www.youtube.com/watch?v=fzhAseXp5B4)\n",
    "im = Image.open('/Users/brodenkirch/Desktop/Figure2_updated.png')\n",
    "\n",
    "try:\n",
    "    im2 = im.convert('P', palette = Image.Palette.ADAPTIVE)\n",
    "except:\n",
    "    #use this for older version of PIL/Pillow if the above line doesn't work, \n",
    "    #though this line will have isolated, extremely minor image effects due to \n",
    "    #only using 256 colors instead of the 3-element RGB scale\n",
    "    im2 = im.convert('P')\n",
    "\n",
    "im2.save('/Users/brodenkirch/Desktop/Figure2_updated.png')\n",
    "im.close()\n",
    "im2.close()\n",
    "\n",
    "print ('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9b559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
